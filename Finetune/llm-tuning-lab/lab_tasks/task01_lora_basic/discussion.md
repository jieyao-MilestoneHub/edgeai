# Task 01 å»¶ä¼¸è¨è«–

é€™äº›å•é¡Œæ—¨åœ¨åŠ æ·±ä½ å° LoRA çš„ç†è§£ã€‚å»ºè­°åœ¨å®Œæˆå¯¦ä½œå¾Œæ€è€ƒé€™äº›å•é¡Œã€‚

---

## ğŸ’¡ ç†è«–æ·±å…¥

### Q1: ç‚ºä»€éº¼é è¨“ç·´æ¬Šé‡æ›´æ–°æ˜¯ä½ç§©çš„ï¼Ÿ

**æ€è€ƒæ–¹å‘ï¼š**
- é è¨“ç·´æ¨¡å‹å·²ç¶“å­¸åˆ°äº†ä»€éº¼ï¼Ÿ
- å¾®èª¿æ™‚æˆ‘å€‘çœŸæ­£åœ¨æ”¹è®Šä»€éº¼ï¼Ÿ
- "å…§åœ¨ç¶­åº¦" (intrinsic dimensionality) æ˜¯ä»€éº¼æ„æ€ï¼Ÿ

**å»¶ä¼¸é–±è®€ï¼š**
- [Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning](https://arxiv.org/abs/2012.13255)

---

### Q2: LoRA çš„ rank æ‡‰è©²å¦‚ä½•é¸æ“‡ï¼Ÿ

**å¯¦é©—å»ºè­°ï¼š**
```bash
# å˜—è©¦ä¸åŒ rank
for rank in 2 4 8 16 32 64; do
    python train_lora_basic.py --rank $rank --output_dir output_r${rank}
done
```

**åˆ†æç¶­åº¦ï¼š**
- åƒæ•¸é‡ vs. æ•ˆèƒ½
- è¨“ç·´é€Ÿåº¦ vs. ç²¾åº¦
- éæ“¬åˆé¢¨éšª

**ä½ çš„ç™¼ç¾ï¼š**
- rank=2: _______________
- rank=8: _______________
- rank=16: _______________
- rank=32: _______________

---

### Q3: ç‚ºä»€éº¼ lora_B åˆå§‹åŒ–ç‚ºé›¶ï¼Ÿ

**å°æ¯”å¯¦é©—ï¼š**
```python
# å¯¦é©— 1: B åˆå§‹åŒ–ç‚ºé›¶ï¼ˆæ¨™æº–åšæ³•ï¼‰
nn.init.zeros_(self.lora_B)

# å¯¦é©— 2: B ä¹Ÿä½¿ç”¨ Kaiming åˆå§‹åŒ–
nn.init.kaiming_uniform_(self.lora_B, a=math.sqrt(5))
```

**æ€è€ƒï¼š**
- å…©ç¨®åˆå§‹åŒ–å°è¨“ç·´æœ‰ä½•å½±éŸ¿ï¼Ÿ
- ç‚ºä»€éº¼é›¶åˆå§‹åŒ–æ›´å¥½ï¼Ÿ
- é€™èˆ‡ã€Œä¸ç ´å£é è¨“ç·´çŸ¥è­˜ã€æœ‰ä½•é—œä¿‚ï¼Ÿ

---

## ğŸ”¬ å¯¦ä½œæ·±åŒ–

### Q4: LoRA å¯ä»¥æ‡‰ç”¨åˆ°å“ªäº›å±¤ï¼Ÿ

**ç•¶å‰å¯¦ä½œï¼š**
```python
# åªå° attention å±¤ä½¿ç”¨ LoRA
target_modules = ['c_attn', 'c_proj']
```

**å¯¦é©—ï¼š**
```python
# å¯¦é©— 1: åªå° Q, V
target_modules = ['q_proj', 'v_proj']

# å¯¦é©— 2: å°æ‰€æœ‰ Linear å±¤
target_modules = None

# å¯¦é©— 3: åŒ…å« FFN
target_modules = ['c_attn', 'c_proj', 'c_fc']
```

**ä½ çš„çµè«–ï¼š**
- æœ€å°å¯è¡Œé…ç½®ï¼š_______________
- æœ€ä½³æ€§åƒ¹æ¯”é…ç½®ï¼š_______________
- æ•ˆèƒ½å¤©èŠ±æ¿ï¼š_______________

---

### Q5: Alpha çš„ç¸®æ”¾çœŸçš„å¿…è¦å—ï¼Ÿ

**å¯¦é©—ï¼š**
```python
# ç•¶å‰: output = lora_out * (alpha / rank)
# æ¸¬è©¦: output = lora_out ï¼ˆç„¡ç¸®æ”¾ï¼‰
```

**è§€å¯ŸæŒ‡æ¨™ï¼š**
- è¨“ç·´ç©©å®šæ€§
- æ”¶æ–‚é€Ÿåº¦
- æœ€çµ‚æ•ˆèƒ½

**ä½ çš„ç™¼ç¾ï¼š**
______________________________

---

### Q6: åˆä½µæ¬Šé‡å¾Œæ€§èƒ½æœ‰å·®ç•°å—ï¼Ÿ

**é©—è­‰å¯¦é©—ï¼š**
```python
# æ¸¬è©¦ 1: æœªåˆä½µ
model.eval()
loss_unmerged = evaluate(model, dataloader)

# æ¸¬è©¦ 2: åˆä½µå¾Œ
for module in model.modules():
    if isinstance(module, LinearWithLoRA):
        module.merge_weights()
loss_merged = evaluate(model, dataloader)

# æ¯”è¼ƒå·®ç•°
print(f"Difference: {abs(loss_merged - loss_unmerged)}")
```

**é æœŸçµæœï¼š**
å·®ç•°æ‡‰è©² < 1e-6ï¼ˆæ•¸å€¼èª¤å·®ç¯„åœå…§ï¼‰

---

## ğŸš€ æ•ˆèƒ½å„ªåŒ–

### Q7: å¦‚ä½•æ¸›å°‘è¨˜æ†¶é«”ä½¿ç”¨ï¼Ÿ

**ç­–ç•¥ï¼š**

1. **æ¢¯åº¦ç´¯ç©**
   ```python
   for i, batch in enumerate(dataloader):
       loss = model(**batch).loss / accumulation_steps
       loss.backward()
       if (i + 1) % accumulation_steps == 0:
           optimizer.step()
           optimizer.zero_grad()
   ```

2. **æ··åˆç²¾åº¦è¨“ç·´**
   ```python
   from torch.cuda.amp import autocast, GradScaler
   scaler = GradScaler()
   with autocast():
       loss = model(**batch).loss
   scaler.scale(loss).backward()
   ```

3. **Gradient Checkpointing**
   ```python
   model.gradient_checkpointing_enable()
   ```

**å¯¦é©—çµæœï¼š**
| æ–¹æ³• | è¨˜æ†¶é«”ä½¿ç”¨ | è¨“ç·´æ™‚é–“ |
|------|-----------|---------|
| åŸºæº– | _______ | _______ |
| + æ¢¯åº¦ç´¯ç© | _______ | _______ |
| + æ··åˆç²¾åº¦ | _______ | _______ |
| + Checkpoint | _______ | _______ |

---

### Q8: LoRA èƒ½ç”¨æ–¼æ¨è«–åŠ é€Ÿå—ï¼Ÿ

**æ€è€ƒï¼š**
- åˆä½µæ¬Šé‡å‰å¾Œçš„æ¨è«–é€Ÿåº¦
- å¤š adapter å ´æ™¯çš„å„ªå‹¢
- èˆ‡å…¶ä»–åŠ é€ŸæŠ€è¡“ï¼ˆpruning, quantizationï¼‰çš„å°æ¯”

**ä½ çš„çœ‹æ³•ï¼š**
______________________________

---

## ğŸ—ï¸ ç³»çµ±è¨­è¨ˆ

### Q9: å¦‚ä½•è¨­è¨ˆå¤šä»»å‹™ LoRA ç³»çµ±ï¼Ÿ

**å ´æ™¯ï¼š**
éœ€è¦ç‚º 10 å€‹ä¸åŒä»»å‹™åˆ†åˆ¥å¾®èª¿æ¨¡å‹ã€‚

**è¨­è¨ˆè€ƒé‡ï¼š**
1. å¦‚ä½•å„²å­˜ 10 å€‹ adapterï¼Ÿ
2. å¦‚ä½•å‹•æ…‹è¼‰å…¥ä¸åŒ adapterï¼Ÿ
3. å¦‚ä½•å¯¦ç¾ batchingï¼ˆåŒä¸€ batch ä¸åŒ adapterï¼‰ï¼Ÿ

**ä½ çš„è¨­è¨ˆï¼š**
______________________________

---

### Q10: LoRA èˆ‡ Adapterã€Prefix-tuning çš„å°æ¯”ï¼Ÿ

**å°æ¯”ç¶­åº¦ï¼š**
| æ–¹æ³• | åƒæ•¸é‡ | æ¨è«–å»¶é² | è¨“ç·´é€Ÿåº¦ | æ•ˆèƒ½ |
|------|--------|---------|---------|------|
| LoRA | ______ | ______ | ______ | ____ |
| Adapter | ______ | ______ | ______ | ____ |
| Prefix-tuning | ______ | ______ | ______ | ____ |

**ä½ çš„é¸æ“‡æ¨™æº–ï¼š**
______________________________

---

## ğŸ“ˆ é€²éšæ‡‰ç”¨

### Q11: èƒ½å¦å¯¦ä½œå‹•æ…‹ rankï¼ˆAdaLoRAï¼‰ï¼Ÿ

**æƒ³æ³•ï¼š**
ä¸åŒå±¤ä½¿ç”¨ä¸åŒ rankï¼Œç”šè‡³è¨“ç·´ä¸­å‹•æ…‹èª¿æ•´ã€‚

**å½ä»£ç¢¼ï¼š**
```python
# æ ¹æ“šé‡è¦æ€§åˆ†é… rank
importance_scores = compute_importance(model)
for layer, score in zip(model.layers, importance_scores):
    layer.lora.rank = allocate_rank(score)
```

**æŒ‘æˆ°ï¼š**
______________________________

---

### Q12: LoRA èƒ½ç”¨æ–¼ Vision Transformer å—ï¼Ÿ

**æ€è€ƒï¼š**
- ViT çš„æ¶æ§‹èˆ‡ LLM çš„ç•°åŒ
- å“ªäº›å±¤æ‡‰è©²ä½¿ç”¨ LoRA
- æ•ˆèƒ½æœƒå¦‚ä½•

**å¯¦é©—è¨ˆç•«ï¼š**
______________________________

---

## ğŸ¯ ç¸½çµæ€è€ƒ

### å®Œæˆé€™å€‹ Task å¾Œï¼Œä½ æœ€å¤§çš„æ”¶ç©«æ˜¯ä»€éº¼ï¼Ÿ

______________________________

### é‚„æœ‰å“ªäº›ä¸ç†è§£çš„åœ°æ–¹ï¼Ÿ

______________________________

### ä¸‹ä¸€æ­¥ä½ æƒ³æ¢ç´¢ä»€éº¼ï¼Ÿ

______________________________

---

## ğŸ“š æ¨è–¦é–±è®€

### å¿…è®€è«–æ–‡
1. LoRA (åŸå§‹è«–æ–‡)
2. QLoRA (é‡åŒ– + LoRA)
3. AdaLoRA (è‡ªé©æ‡‰ rank)

### å¯¦ä½œè³‡æº
1. Hugging Face PEFT åº«
2. Microsoft LoRA å®˜æ–¹å¯¦ä½œ
3. vLLM çš„ LoRA æ”¯æ´

---

**æ€è€ƒé€™äº›å•é¡Œå°‡å¹«åŠ©ä½ æ·±å…¥ç†è§£ LoRAï¼Œè€Œä¸åƒ…åƒ…æ˜¯ä½¿ç”¨å®ƒï¼ğŸš€**
