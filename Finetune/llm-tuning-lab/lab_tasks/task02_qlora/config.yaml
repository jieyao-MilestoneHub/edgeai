# QLoRA Training Configuration
# 針對 Qwen2.5-3B 在 GTX 4060 (8GB) 上的優化配置

# ==================== 模型配置 ====================
model:
  name: "Qwen/Qwen2.5-3B-Instruct"  # 模型名稱（Hugging Face ID）
  trust_remote_code: true            # Qwen 需要信任遠端程式碼

# ==================== 量化配置 ====================
quantization:
  load_in_4bit: true                 # 使用 4-bit 量化
  quant_type: "nf4"                  # NF4 格式（針對正態分布優化）
  compute_dtype: "bfloat16"          # 計算時使用 BF16（穩定性）
  use_double_quant: true             # 啟用雙重量化（額外節省 8%）

# ==================== LoRA 超參數 ====================
lora:
  rank: 16                           # LoRA rank（低秩維度）
  alpha: 32.0                        # 縮放因子（通常 = 2 × rank）
  dropout: 0.05                      # Dropout 比例
  target_modules:                    # 目標層（Attention + MLP）
    - "q_proj"                       # Query 投影
    - "k_proj"                       # Key 投影
    - "v_proj"                       # Value 投影
    - "o_proj"                       # Output 投影
    - "gate_proj"                    # Gate 投影 (MLP)
    - "up_proj"                      # Up 投影 (MLP)
    - "down_proj"                    # Down 投影 (MLP)

# ==================== 訓練超參數 ====================
training:
  # 基礎設定
  num_epochs: 3                      # 訓練輪數
  batch_size: 1                      # Per-device batch size（8GB 顯卡建議 1）
  gradient_accumulation_steps: 16    # 梯度累積步數（有效 batch_size = 1×16 = 16）
  learning_rate: 2.0e-4              # 學習率（QLoRA 可用較高學習率）
  weight_decay: 0.01                 # 權重衰減

  # 學習率調整
  warmup_ratio: 0.1                  # Warmup 比例（10% 步數）
  lr_scheduler_type: "cosine"        # 學習率調度器類型

  # 記憶體優化
  gradient_checkpointing: true       # 梯度檢查點（節省記憶體 30-50%）
  optim: "paged_adamw_8bit"          # 分頁優化器（降低記憶體峰值）

  # 精度設定
  fp16: false                        # 不使用 FP16
  bf16: true                         # 使用 BF16（更穩定）

  # 其他設定
  max_grad_norm: 1.0                 # 梯度裁剪
  logging_steps: 10                  # 日誌間隔
  save_steps: 500                    # 儲存間隔
  save_total_limit: 2                # 保留最近 2 個 checkpoint
  eval_steps: 250                    # 評估間隔

# ==================== 數據配置 ====================
data:
  dataset_name: "wikitext"           # 資料集名稱
  dataset_config: "wikitext-2-raw-v1"  # 資料集配置
  max_length: 512                    # 最大序列長度
  train_split: "train"               # 訓練集分割
  eval_split: "validation"           # 驗證集分割
  num_workers: 4                     # 資料載入 workers

  # 資料處理
  preprocessing_num_proc: 4          # 預處理並行數
  remove_unused_columns: true        # 移除未使用的列

# ==================== 輸出配置 ====================
output:
  dir: "./output_qlora_qwen_3b"      # 輸出目錄
  logging_dir: "./logs"              # TensorBoard 日誌目錄
  overwrite_output_dir: true         # 覆寫輸出目錄

  # 結果儲存
  save_adapter_only: true            # 只儲存 LoRA adapter（節省空間）
  save_training_log: true            # 儲存訓練日誌
  save_training_curves: true         # 儲存訓練曲線圖

# ==================== 進階設定 ====================
advanced:
  # 隨機種子
  seed: 42                           # 隨機種子（可重現性）

  # TensorFlow 32 加速（Ampere 架構及以上）
  allow_tf32: true                   # 啟用 TF32 加速

  # 分散式訓練（多卡）
  ddp_find_unused_parameters: false  # DDP 設定

  # 推論設定
  generation_max_length: 128         # 生成最大長度
  generation_temperature: 0.7        # 生成溫度
  generation_top_p: 0.9              # Top-p 採樣

# ==================== Hugging Face Hub（可選）====================
hub:
  push_to_hub: false                 # 是否上傳到 HF Hub
  hub_model_id: "your-username/qwen-qlora"  # HF 模型 ID
  hub_private_repo: false            # 是否設為私有
  hub_strategy: "end"                # 上傳策略（end/checkpoint/every_save）

# ==================== 備註 ====================
# 記憶體使用估算（Qwen2.5-3B, batch_size=1, seq_len=512）：
#   - 量化模型：~1.5 GB
#   - LoRA 參數：~50 MB
#   - Optimizer states：~100 MB
#   - Activations：~1.5 GB (with gradient checkpointing)
#   - 總計：~3.2 GB（8GB 顯卡安全）
#
# 調整建議：
#   - GPU 記憶體不足：降低 max_length 或 batch_size
#   - 訓練太慢：增加 gradient_accumulation_steps 或 batch_size
#   - 準確率不佳：增加 lora.rank 或 training.num_epochs
#   - 過擬合：增加 lora.dropout 或減少 training.num_epochs
