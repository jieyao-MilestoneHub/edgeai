# QLoRA Training Requirements
# Task 02 - Qwen2.5-3B with 4-bit Quantization

# Core Dependencies
torch>=2.0.0                # PyTorch 2.0+ (支援 BF16 和 TF32)
transformers>=4.36.0        # Hugging Face Transformers (支援 BitsAndBytes)
datasets>=2.14.0            # Hugging Face Datasets
accelerate>=0.25.0          # 加速訓練與推論
peft>=0.7.0                 # Parameter-Efficient Fine-Tuning (LoRA)

# Quantization
bitsandbytes>=0.41.0        # 4-bit/8-bit 量化核心庫
                            # 重要：需要 CUDA 11.8+ 和相容的 GPU

# Utilities
pyyaml>=6.0                 # YAML 配置檔解析
tqdm>=4.65.0                # 進度條
numpy>=1.24.0               # 數值計算
scipy>=1.10.0               # 科學計算（NF4 分位數）

# Visualization
matplotlib>=3.7.0           # 繪製訓練曲線
tensorboard>=2.13.0         # TensorBoard 日誌

# Optional: Performance
einops>=0.6.1               # Einstein 記號操作（某些模型需要）
sentencepiece>=0.1.99       # Tokenizer（某些模型需要）
protobuf>=3.20.0            # Protocol Buffers

# Development Tools (可選)
ipython>=8.12.0             # 互動式 Python shell
jupyter>=1.0.0              # Jupyter Notebook
black>=23.0.0               # Code formatter
flake8>=6.0.0               # Linter

# 安裝說明：
# 1. 基礎安裝（CPU 或已有 CUDA）：
#    pip install -r requirements.txt
#
# 2. GPU 訓練（需要 CUDA 11.8+）：
#    - 先安裝 PyTorch with CUDA:
#      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
#    - 再安裝其他依賴:
#      pip install -r requirements.txt
#
# 3. 驗證安裝：
#    python -c "import torch; print(torch.cuda.is_available())"
#    python -c "import bitsandbytes; print('BitsAndBytes OK')"
#
# 硬體需求：
# - GPU: NVIDIA GPU with CUDA support (建議 8GB+ VRAM)
# - RAM: 16GB+ (推薦 32GB)
# - 硬碟: 10GB+ 可用空間（模型 + 數據集）
#
# 支援的 GPU：
# - RTX 30 系列: 3060 (12GB), 3070 (8GB), 3080 (10GB/12GB), 3090 (24GB)
# - RTX 40 系列: 4060 (8GB), 4070 (12GB), 4080 (16GB), 4090 (24GB)
# - Tesla 系列: V100 (16GB/32GB), A100 (40GB/80GB)
# - GTX 系列: 1080 Ti (11GB), 1060 (6GB) - 可能需要降低 batch_size
#
# 相容性注意事項：
# - bitsandbytes 需要 Linux 或 WSL2 (Windows Subsystem for Linux)
# - Windows 原生支援有限，建議使用 WSL2 或 Docker
# - macOS 不支援 bitsandbytes（Apple Silicon 可用 MPS，但效果有限）
