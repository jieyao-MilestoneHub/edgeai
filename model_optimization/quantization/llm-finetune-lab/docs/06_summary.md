# 量化技術總結與最佳實踐

> Quantization Techniques Summary and Best Practices
> 整合 PTQ、QAT、混合精度的完整量化策略指南

---

## 學習目標

完成本章後,你將能夠:

- 系統性理解量化技術的全貌
- 根據實際場景選擇最佳量化策略
- 設計端到端的量化流程
- 掌握量化模型的評測與調優方法
- 避免常見的量化陷阱

---

## 量化技術地圖

### 本實驗室涵蓋的技術範圍

```
模型優化技術分類 (本實驗室範圍)

1. 參數高效微調 (Parameter-Efficient Fine-Tuning)
   └─ LoRA
       - 目標: 減少微調時的可訓練參數
       - 方法: 低秩矩陣分解 W' = W₀ + BA

2. 量化技術 (Quantization)
   ├─ PTQ (Post-Training Quantization)
   │   ├─ 基礎 PTQ: 訓練後直接量化
   │   └─ NF4 量化: 針對正態分布優化的 4-bit 格式
   │
   ├─ Precision-Aware Training
   │   - 目標: 識別敏感層,設計混合精度配置
   │   - 方法: 敏感度分析 (SQNR, Hessian-based)
   │
   └─ QAT (Quantization-Aware Training)
       - 目標: 訓練時適應量化誤差
       - 方法: Fake Quantization + STE

3. 組合技術
   └─ QLoRA = LoRA + 量化 (NF4 PTQ)
       - 凍結權重用 NF4 量化 (4-bit)
       - LoRA 參數保持高精度 (BF16)
       - 用途: 在有限 GPU 上微調大模型
```

**技術關係釐清**:

| 技術 | 分類 | 核心目標 | 關鍵技術 |
|------|------|---------|---------|
| **LoRA** | 參數高效微調 | 減少可訓練參數量 | 低秩分解 |
| **NF4/PTQ** | 量化 | 壓縮模型儲存空間 | 分位數量化 |
| **QLoRA** | **組合技術** | 同時達成微調與壓縮 | LoRA + NF4 量化 |
| **Precision-Aware** | 量化策略 | 最佳混合精度配置 | 敏感度分析 |
| **QAT** | 量化訓練 | 提升量化後精度 | 假量化 + STE |

**重要澄清**:
- QLoRA **不是**單純的參數高效微調技術
- QLoRA **不是**單純的量化技術
- QLoRA 是 **LoRA (參數高效) + NF4 量化 (模型壓縮)** 的組合
- 本實驗室從 LoRA 開始,是因為理解 LoRA 是學習 QLoRA 的前提

---

## 本實驗室的學習路徑邏輯

### 為什麼按照 LoRA → QLoRA → Precision-Aware → QAT 的順序?

```
階段 1: LoRA (Task 01)
目標: 理解參數高效微調
問題: 可訓練參數減少了,但凍結權重仍佔大量記憶體
       
       ↓ 自然引出

階段 2: QLoRA (Task 02)
目標: 壓縮凍結權重
技術: LoRA + NF4 量化
問題: 僅適用於訓練階段,部署時仍需完整權重
       或者直接 4-bit 量化精度下降嚴重

       ↓ 自然引出

階段 3: Precision-Aware (Task 03)
目標: 找出哪些層可以用低精度
技術: 敏感度分析 + 混合精度配置
問題: PTQ 在極低精度 (INT4) 下精度損失過大

       ↓ 自然引出

階段 4: QAT (Task 04)
目標: 訓練時適應量化誤差
技術: Fake Quantization + STE
成果: INT4 量化精度接近 INT8

       ↓ 整合

階段 5: 綜合應用 (Task 05)
整合所有技術,完成端到端量化流程
```

**技術演進的內在邏輯**:
1. LoRA 解決「訓練參數量」問題
2. QLoRA 解決「訓練記憶體」問題 (凍結權重壓縮)
3. Precision-Aware 解決「部署記憶體」問題 (混合精度配置)
4. QAT 解決「部署精度」問題 (適應低精度)

---

## 量化決策樹:精確的技術選擇

### 決策流程 (基於實際需求)

```
Q1: 你的目標是什麼?
    │
    ├─ 微調大模型 (記憶體不足)
    │   │
    │   └─ 使用 QLoRA
    │       - 凍結權重: NF4 量化
    │       - LoRA 參數: BF16
    │       - 適用: 訓練階段
    │
    └─ 部署模型 (推論加速)
        │
        └─ Q2: 目標量化精度?
            │
            ├─ INT8
            │   │
            │   └─ Q3: 有訓練資源?
            │       │
            │       ├─ 有 → QAT INT8 (精度最佳)
            │       └─ 無 → PTQ INT8 (快速量化)
            │
            └─ INT4 或更低
                │
                └─ Q4: 能接受精度損失?
                    │
                    ├─ < 1% → 必須用 QAT + 混合精度
                    │          (Attention INT8, FFN INT4)
                    │
                    └─ 1-3% → PTQ + 混合精度
                               (根據敏感度分析配置)
```

---

## 技術適用場景:精確對照表

### 場景 1: 在 24GB GPU 上微調 LLaMA-7B

**需求分析**:
```
模型: LLaMA-7B (14GB FP16 權重)
硬體: RTX 4090 (24GB VRAM)
目標: 能夠訓練
```

**技術選擇**: QLoRA

**原因**:
- LoRA 僅能減少可訓練參數 (0.6GB),凍結權重仍需 14GB
- 全參數微調需要 14GB + 28GB (optimizer) + 梯度 ≈ 50GB ❌
- LoRA 微調需要 14GB + 1GB (optimizer) + 激活值 ≈ 24GB ⚠️ 勉強
- **QLoRA 微調需要 3.5GB (NF4) + 1GB (optimizer) + 激活值 ≈ 10GB ✅**

**關鍵**: QLoRA 的量化是為了**訓練階段的記憶體優化**

---

### 場景 2: 部署 LLaMA-7B 到 Jetson Orin (32GB)

**需求分析**:
```
模型: LLaMA-7B 微調後
硬體: Jetson Orin (32GB 共享記憶體)
目標: 推論加速,記憶體 < 5GB
```

**技術選擇**: Precision-Aware (混合精度) + QAT

**步驟**:
1. 敏感度分析識別關鍵層
2. 配置混合精度: Attention INT8, FFN INT4
3. QAT 訓練 2 epochs
4. 轉換為真正的 INT 模型

**不選擇 QLoRA 的原因**:
- QLoRA 的 NF4 量化僅用於訓練階段
- 推論時需要轉換為標準 INT4/INT8
- QLoRA 不包含 QAT,無法優化部署精度

---

### 場景 3: 快速量化 BERT-base (無訓練資源)

**需求分析**:
```
模型: BERT-base (110M 參數)
限制: 無 GPU,無訓練資源
目標: 快速量化,模型大小減半
```

**技術選擇**: PTQ INT8

**工具**:
```python
import torch.quantization as quant

model.qconfig = quant.get_default_qconfig('fbgemm')
quant.prepare(model, inplace=True)

# 校準
for batch in calib_data:
    model(**batch)

quant.convert(model, inplace=True)
```

**結果**:
- 模型大小: 440MB → 110MB
- 精度下降: < 0.5%
- 量化時間: < 10 分鐘

---

## 技術組合:實戰策略

### 策略 1: 微調 + 部署一體化

**場景**: 從微調到部署的完整流程

```
Step 1: 微調階段 (GPU 記憶體受限)
→ 使用 QLoRA
→ 輸出: LoRA adapter (30MB)

Step 2: 合併模型
→ 合併 adapter 到 base model
→ 輸出: 微調後的 FP16 模型 (14GB)

Step 3: 部署量化 (記憶體 < 5GB)
→ 敏感度分析 + 混合精度配置
→ QAT 訓練適應量化
→ 輸出: INT4/INT8 混合精度模型 (4.5GB)
```

**關鍵理解**:
- QLoRA 用於訓練階段 (Task 02)
- Precision-Aware + QAT 用於部署階段 (Task 03-04)
- **兩者目標不同,不能混淆**

---

### 策略 2: 純推論優化 (已有 FP16 模型)

**場景**: 已有訓練好的模型,需要部署優化

```
Step 1: 評估基準
→ 測試 FP16 模型精度
→ 確定可接受的精度損失範圍

Step 2: 敏感度分析
→ 逐層量化測試
→ 識別敏感層

Step 3: 選擇方案
→ 精度要求高: QAT
→ 快速部署: PTQ + 混合精度

Step 4: 量化實施
→ 應用選定的量化策略
→ 評測與調優
```

---

## 效能基準:實測數據

### LLaMA-7B 不同方案對比

| 階段 | 技術方案 | 模型大小 | MMLU | 適用場景 |
|------|---------|---------|------|---------|
| **訓練** | 全參數微調 (FP16) | 14 GB | 73.2% | 基準 |
| **訓練** | LoRA (FP16) | 14 GB + 0.5 GB | 73.0% | 減少可訓練參數 |
| **訓練** | **QLoRA (NF4)** | **3.5 GB + 0.5 GB** | **72.8%** | **記憶體受限訓練** ✅ |
| **部署** | FP16 | 14 GB | 73.2% | 基準 |
| **部署** | PTQ INT8 | 7 GB | 72.8% | 快速量化 |
| **部署** | PTQ INT4 | 3.5 GB | 68.3% | 精度損失大 ❌ |
| **部署** | **QAT INT4 + 混合精度** | **4.5 GB** | **71.8%** | **最佳部署方案** ✅ |

**數據解讀**:
- QLoRA 在**訓練階段**記憶體最優 (3.5GB)
- QAT + 混合精度在**部署階段**精度最優 (71.8% vs 68.3%)
- 兩者解決不同階段的問題,**不能直接比較**

---

## 常見誤解澄清

### 誤解 1: "QLoRA 就是量化技術"

❌ **錯誤**: QLoRA 是量化技術的一種

✅ **正確**: 
- QLoRA = LoRA (參數高效微調) + NF4 量化 (模型壓縮)
- QLoRA 主要用於**訓練階段**降低記憶體需求
- 推論時仍需標準量化技術 (PTQ/QAT)

---

### 誤解 2: "用 QLoRA 訓練後,部署時自動量化"

❌ **錯誤**: QLoRA 訓練=量化部署

✅ **正確**:
- QLoRA 訓練輸出的是 LoRA adapter + base model
- 合併後得到 FP16 完整模型
- 部署時需要**另外**進行量化 (PTQ 或 QAT)
- QLoRA 的 NF4 量化僅用於訓練階段的凍結權重

---

### 誤解 3: "Precision-Aware 是一種量化方法"

❌ **錯誤**: Precision-Aware 是量化算法

✅ **正確**:
- Precision-Aware 是**量化策略**,不是量化方法
- 它用於決定「哪些層用什麼精度」
- 需要配合 PTQ 或 QAT 實際執行量化
- 輸出的是配置策略,不是量化模型

---

## 技術選擇速查表

### 根據需求快速選擇

| 你的需求 | 推薦技術 | 原因 |
|---------|---------|------|
| 微調大模型,GPU 記憶體不足 | QLoRA | 壓縮凍結權重,降低訓練記憶體 |
| 部署模型,目標 INT8 | PTQ INT8 | 快速,精度損失小 |
| 部署模型,目標 INT4,要求高精度 | QAT + 混合精度 | 訓練適應量化,最小精度損失 |
| 快速量化,無訓練資源 | PTQ + 敏感度分析 | 無需訓練,混合精度補償 |
| 極致壓縮,可接受精度損失 | PTQ INT4 | 最小模型,最快推論 |

---

## 總結:精確的技術定位

### 核心原則

1. **區分訓練與部署**
   - 訓練階段優化: LoRA, QLoRA
   - 部署階段優化: PTQ, QAT, 混合精度

2. **理解技術組合**
   - QLoRA ≠ 單純量化
   - QLoRA = LoRA + 量化 (訓練用)
   - 部署仍需 PTQ/QAT

3. **根據階段選擇**
   - 微調階段: 記憶體優先 → QLoRA
   - 部署階段: 精度與速度平衡 → QAT + 混合精度

---

### 本實驗室的定位

**我們專注於**:
- ✅ 量化的數學原理
- ✅ PTQ, QAT, 混合精度的實作
- ✅ LoRA 與量化的關係
- ✅ 模型層面的優化技術

**我們不涉及**:
- ❌ 推論引擎 (TensorRT, ONNX)
- ❌ 服務化部署
- ❌ 分散式訓練系統
- ❌ MLOps 工程實踐

**下一步學習建議**:
```
完成本實驗室
    ↓
理解量化原理與實作
    ↓
學習推論引擎 (TensorRT/ONNX)
    ↓
整合到生產系統
```

---

> **關鍵啟示**
>
> 量化技術不是孤立的,而是與參數高效微調、混合精度等技術協同工作。
>
> 理解每個技術的**精確定位**和**適用階段**,才能在實際專案中做出正確決策。
>
> 本實驗室的目標是讓你**理解原理**,而非記憶配方 — 
> 只有理解了技術的本質,才能靈活應對各種實際場景。

---

> **祝你成為真正理解量化技術的 Edge AI 工程師!** 🚀
