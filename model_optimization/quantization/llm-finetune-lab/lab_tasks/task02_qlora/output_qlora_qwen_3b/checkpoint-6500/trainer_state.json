{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.8322893403780163,
  "eval_steps": 250,
  "global_step": 6500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004357535813497467,
      "grad_norm": 1.0347124338150024,
      "learning_rate": 2.612481857764877e-06,
      "loss": 2.8067,
      "step": 10
    },
    {
      "epoch": 0.008715071626994935,
      "grad_norm": 1.148348331451416,
      "learning_rate": 5.515239477503629e-06,
      "loss": 2.8775,
      "step": 20
    },
    {
      "epoch": 0.013072607440492401,
      "grad_norm": 1.158178687095642,
      "learning_rate": 8.41799709724238e-06,
      "loss": 2.7679,
      "step": 30
    },
    {
      "epoch": 0.01743014325398987,
      "grad_norm": 0.6468489766120911,
      "learning_rate": 1.1320754716981132e-05,
      "loss": 2.7051,
      "step": 40
    },
    {
      "epoch": 0.021787679067487336,
      "grad_norm": 0.9221354722976685,
      "learning_rate": 1.4223512336719886e-05,
      "loss": 2.8534,
      "step": 50
    },
    {
      "epoch": 0.026145214880984802,
      "grad_norm": 1.1303173303604126,
      "learning_rate": 1.7126269956458638e-05,
      "loss": 2.7705,
      "step": 60
    },
    {
      "epoch": 0.03050275069448227,
      "grad_norm": 2.474148750305176,
      "learning_rate": 2.0029027576197386e-05,
      "loss": 2.7396,
      "step": 70
    },
    {
      "epoch": 0.03486028650797974,
      "grad_norm": 1.1396121978759766,
      "learning_rate": 2.293178519593614e-05,
      "loss": 2.685,
      "step": 80
    },
    {
      "epoch": 0.039217822321477205,
      "grad_norm": 1.0906873941421509,
      "learning_rate": 2.5834542815674896e-05,
      "loss": 2.5416,
      "step": 90
    },
    {
      "epoch": 0.04357535813497467,
      "grad_norm": 1.091058611869812,
      "learning_rate": 2.8737300435413644e-05,
      "loss": 2.5388,
      "step": 100
    },
    {
      "epoch": 0.04793289394847214,
      "grad_norm": 1.499975323677063,
      "learning_rate": 3.1640058055152396e-05,
      "loss": 2.5387,
      "step": 110
    },
    {
      "epoch": 0.052290429761969605,
      "grad_norm": 1.7572134733200073,
      "learning_rate": 3.454281567489115e-05,
      "loss": 2.4389,
      "step": 120
    },
    {
      "epoch": 0.05664796557546707,
      "grad_norm": 1.2177666425704956,
      "learning_rate": 3.74455732946299e-05,
      "loss": 2.4113,
      "step": 130
    },
    {
      "epoch": 0.06100550138896454,
      "grad_norm": 0.8224694728851318,
      "learning_rate": 4.0348330914368655e-05,
      "loss": 2.3627,
      "step": 140
    },
    {
      "epoch": 0.065363037202462,
      "grad_norm": 0.7771422863006592,
      "learning_rate": 4.32510885341074e-05,
      "loss": 2.3188,
      "step": 150
    },
    {
      "epoch": 0.06972057301595948,
      "grad_norm": 0.7613596320152283,
      "learning_rate": 4.615384615384616e-05,
      "loss": 2.3974,
      "step": 160
    },
    {
      "epoch": 0.07407810882945694,
      "grad_norm": 0.9067203998565674,
      "learning_rate": 4.9056603773584906e-05,
      "loss": 2.4083,
      "step": 170
    },
    {
      "epoch": 0.07843564464295441,
      "grad_norm": 1.0891414880752563,
      "learning_rate": 5.1959361393323655e-05,
      "loss": 2.4197,
      "step": 180
    },
    {
      "epoch": 0.08279318045645187,
      "grad_norm": 1.1392865180969238,
      "learning_rate": 5.486211901306241e-05,
      "loss": 2.4128,
      "step": 190
    },
    {
      "epoch": 0.08715071626994934,
      "grad_norm": 1.2895429134368896,
      "learning_rate": 5.7764876632801165e-05,
      "loss": 2.3646,
      "step": 200
    },
    {
      "epoch": 0.09150825208344682,
      "grad_norm": 0.9575309157371521,
      "learning_rate": 6.066763425253992e-05,
      "loss": 2.3366,
      "step": 210
    },
    {
      "epoch": 0.09586578789694428,
      "grad_norm": 1.488203525543213,
      "learning_rate": 6.357039187227866e-05,
      "loss": 2.4051,
      "step": 220
    },
    {
      "epoch": 0.10022332371044175,
      "grad_norm": 1.3795249462127686,
      "learning_rate": 6.647314949201742e-05,
      "loss": 2.3375,
      "step": 230
    },
    {
      "epoch": 0.10458085952393921,
      "grad_norm": 1.1918649673461914,
      "learning_rate": 6.937590711175617e-05,
      "loss": 2.3511,
      "step": 240
    },
    {
      "epoch": 0.10893839533743668,
      "grad_norm": 1.6895438432693481,
      "learning_rate": 7.227866473149493e-05,
      "loss": 2.3661,
      "step": 250
    },
    {
      "epoch": 0.10893839533743668,
      "eval_loss": NaN,
      "eval_runtime": 1031.5356,
      "eval_samples_per_second": 3.645,
      "eval_steps_per_second": 3.645,
      "step": 250
    },
    {
      "epoch": 0.11329593115093414,
      "grad_norm": 1.7214585542678833,
      "learning_rate": 7.518142235123368e-05,
      "loss": 2.419,
      "step": 260
    },
    {
      "epoch": 0.11765346696443162,
      "grad_norm": 0.8643900752067566,
      "learning_rate": 7.808417997097243e-05,
      "loss": 2.3409,
      "step": 270
    },
    {
      "epoch": 0.12201100277792908,
      "grad_norm": 0.9730822443962097,
      "learning_rate": 8.098693759071118e-05,
      "loss": 2.3927,
      "step": 280
    },
    {
      "epoch": 0.12636853859142655,
      "grad_norm": 1.777951717376709,
      "learning_rate": 8.388969521044994e-05,
      "loss": 2.3482,
      "step": 290
    },
    {
      "epoch": 0.130726074404924,
      "grad_norm": 1.0706822872161865,
      "learning_rate": 8.679245283018869e-05,
      "loss": 2.3289,
      "step": 300
    },
    {
      "epoch": 0.1350836102184215,
      "grad_norm": 1.2614797353744507,
      "learning_rate": 8.969521044992744e-05,
      "loss": 2.3882,
      "step": 310
    },
    {
      "epoch": 0.13944114603191896,
      "grad_norm": 1.2038369178771973,
      "learning_rate": 9.259796806966619e-05,
      "loss": 2.2828,
      "step": 320
    },
    {
      "epoch": 0.14379868184541642,
      "grad_norm": 1.1090466976165771,
      "learning_rate": 9.550072568940493e-05,
      "loss": 2.2859,
      "step": 330
    },
    {
      "epoch": 0.14815621765891387,
      "grad_norm": 0.7537197470664978,
      "learning_rate": 9.84034833091437e-05,
      "loss": 2.2009,
      "step": 340
    },
    {
      "epoch": 0.15251375347241136,
      "grad_norm": 1.059146761894226,
      "learning_rate": 0.00010130624092888243,
      "loss": 2.3328,
      "step": 350
    },
    {
      "epoch": 0.15687128928590882,
      "grad_norm": 1.0050591230392456,
      "learning_rate": 0.0001042089985486212,
      "loss": 2.3222,
      "step": 360
    },
    {
      "epoch": 0.16122882509940628,
      "grad_norm": 1.2810499668121338,
      "learning_rate": 0.00010711175616835995,
      "loss": 2.4231,
      "step": 370
    },
    {
      "epoch": 0.16558636091290374,
      "grad_norm": 1.7446677684783936,
      "learning_rate": 0.0001100145137880987,
      "loss": 2.3069,
      "step": 380
    },
    {
      "epoch": 0.16994389672640123,
      "grad_norm": 1.3611527681350708,
      "learning_rate": 0.00011291727140783745,
      "loss": 2.3384,
      "step": 390
    },
    {
      "epoch": 0.1743014325398987,
      "grad_norm": 1.1699717044830322,
      "learning_rate": 0.0001158200290275762,
      "loss": 2.3443,
      "step": 400
    },
    {
      "epoch": 0.17865896835339615,
      "grad_norm": 1.0323320627212524,
      "learning_rate": 0.00011872278664731495,
      "loss": 2.3451,
      "step": 410
    },
    {
      "epoch": 0.18301650416689363,
      "grad_norm": 1.1308039426803589,
      "learning_rate": 0.00012162554426705371,
      "loss": 2.3575,
      "step": 420
    },
    {
      "epoch": 0.1873740399803911,
      "grad_norm": 1.3578388690948486,
      "learning_rate": 0.00012452830188679244,
      "loss": 2.3595,
      "step": 430
    },
    {
      "epoch": 0.19173157579388855,
      "grad_norm": 0.8887565732002258,
      "learning_rate": 0.0001274310595065312,
      "loss": 2.4376,
      "step": 440
    },
    {
      "epoch": 0.196089111607386,
      "grad_norm": 0.6600817441940308,
      "learning_rate": 0.00013033381712626994,
      "loss": 2.3048,
      "step": 450
    },
    {
      "epoch": 0.2004466474208835,
      "grad_norm": 0.9565986394882202,
      "learning_rate": 0.00013323657474600872,
      "loss": 2.3631,
      "step": 460
    },
    {
      "epoch": 0.20480418323438096,
      "grad_norm": 1.2244930267333984,
      "learning_rate": 0.00013613933236574746,
      "loss": 2.3761,
      "step": 470
    },
    {
      "epoch": 0.20916171904787842,
      "grad_norm": 0.9282581806182861,
      "learning_rate": 0.0001390420899854862,
      "loss": 2.3249,
      "step": 480
    },
    {
      "epoch": 0.21351925486137588,
      "grad_norm": 0.9317697882652283,
      "learning_rate": 0.00014194484760522496,
      "loss": 2.3047,
      "step": 490
    },
    {
      "epoch": 0.21787679067487337,
      "grad_norm": 1.309841513633728,
      "learning_rate": 0.0001448476052249637,
      "loss": 2.2512,
      "step": 500
    },
    {
      "epoch": 0.21787679067487337,
      "eval_loss": NaN,
      "eval_runtime": 1033.885,
      "eval_samples_per_second": 3.637,
      "eval_steps_per_second": 3.637,
      "step": 500
    },
    {
      "epoch": 0.22223432648837083,
      "grad_norm": 0.9669588208198547,
      "learning_rate": 0.00014775036284470249,
      "loss": 2.22,
      "step": 510
    },
    {
      "epoch": 0.22659186230186829,
      "grad_norm": 1.0721491575241089,
      "learning_rate": 0.00015065312046444123,
      "loss": 2.3481,
      "step": 520
    },
    {
      "epoch": 0.23094939811536577,
      "grad_norm": 1.6127822399139404,
      "learning_rate": 0.00015355587808417998,
      "loss": 2.3429,
      "step": 530
    },
    {
      "epoch": 0.23530693392886323,
      "grad_norm": 0.844569206237793,
      "learning_rate": 0.00015645863570391873,
      "loss": 2.3211,
      "step": 540
    },
    {
      "epoch": 0.2396644697423607,
      "grad_norm": 0.7370173931121826,
      "learning_rate": 0.0001593613933236575,
      "loss": 2.2647,
      "step": 550
    },
    {
      "epoch": 0.24402200555585815,
      "grad_norm": 0.7950741648674011,
      "learning_rate": 0.00016226415094339625,
      "loss": 2.3682,
      "step": 560
    },
    {
      "epoch": 0.24837954136935564,
      "grad_norm": 0.9132571220397949,
      "learning_rate": 0.000165166908563135,
      "loss": 2.3629,
      "step": 570
    },
    {
      "epoch": 0.2527370771828531,
      "grad_norm": 0.8613224625587463,
      "learning_rate": 0.00016806966618287375,
      "loss": 2.2385,
      "step": 580
    },
    {
      "epoch": 0.25709461299635056,
      "grad_norm": 1.2020225524902344,
      "learning_rate": 0.0001709724238026125,
      "loss": 2.2808,
      "step": 590
    },
    {
      "epoch": 0.261452148809848,
      "grad_norm": 0.6277287006378174,
      "learning_rate": 0.00017387518142235125,
      "loss": 2.116,
      "step": 600
    },
    {
      "epoch": 0.2658096846233455,
      "grad_norm": 1.2213528156280518,
      "learning_rate": 0.00017677793904209,
      "loss": 2.3194,
      "step": 610
    },
    {
      "epoch": 0.270167220436843,
      "grad_norm": 0.770018994808197,
      "learning_rate": 0.00017968069666182874,
      "loss": 2.2982,
      "step": 620
    },
    {
      "epoch": 0.27452475625034045,
      "grad_norm": 1.257821798324585,
      "learning_rate": 0.0001825834542815675,
      "loss": 2.3251,
      "step": 630
    },
    {
      "epoch": 0.2788822920638379,
      "grad_norm": 0.8251439332962036,
      "learning_rate": 0.00018548621190130624,
      "loss": 2.2753,
      "step": 640
    },
    {
      "epoch": 0.28323982787733537,
      "grad_norm": 1.3921257257461548,
      "learning_rate": 0.00018838896952104502,
      "loss": 2.3982,
      "step": 650
    },
    {
      "epoch": 0.28759736369083283,
      "grad_norm": 0.8207403421401978,
      "learning_rate": 0.00019129172714078376,
      "loss": 2.2329,
      "step": 660
    },
    {
      "epoch": 0.2919548995043303,
      "grad_norm": 0.7264546155929565,
      "learning_rate": 0.0001941944847605225,
      "loss": 2.2549,
      "step": 670
    },
    {
      "epoch": 0.29631243531782775,
      "grad_norm": 0.9891113042831421,
      "learning_rate": 0.00019709724238026126,
      "loss": 2.2406,
      "step": 680
    },
    {
      "epoch": 0.3006699711313252,
      "grad_norm": 1.220977783203125,
      "learning_rate": 0.0002,
      "loss": 2.3198,
      "step": 690
    },
    {
      "epoch": 0.3050275069448227,
      "grad_norm": 0.9549993276596069,
      "learning_rate": 0.00019999871457719335,
      "loss": 2.2975,
      "step": 700
    },
    {
      "epoch": 0.3093850427583202,
      "grad_norm": 1.0822328329086304,
      "learning_rate": 0.0001999948583418196,
      "loss": 2.3324,
      "step": 710
    },
    {
      "epoch": 0.31374257857181764,
      "grad_norm": 1.1749966144561768,
      "learning_rate": 0.00019998843139301664,
      "loss": 2.2761,
      "step": 720
    },
    {
      "epoch": 0.3181001143853151,
      "grad_norm": 1.0222848653793335,
      "learning_rate": 0.00019997943389601138,
      "loss": 2.3097,
      "step": 730
    },
    {
      "epoch": 0.32245765019881256,
      "grad_norm": 0.7798519730567932,
      "learning_rate": 0.0001999678660821156,
      "loss": 2.2401,
      "step": 740
    },
    {
      "epoch": 0.32681518601231,
      "grad_norm": 0.7945012450218201,
      "learning_rate": 0.00019995372824871993,
      "loss": 2.3098,
      "step": 750
    },
    {
      "epoch": 0.32681518601231,
      "eval_loss": NaN,
      "eval_runtime": 1034.2335,
      "eval_samples_per_second": 3.636,
      "eval_steps_per_second": 3.636,
      "step": 750
    },
    {
      "epoch": 0.3311727218258075,
      "grad_norm": 0.6645206212997437,
      "learning_rate": 0.00019993702075928618,
      "loss": 2.3409,
      "step": 760
    },
    {
      "epoch": 0.335530257639305,
      "grad_norm": 1.6763160228729248,
      "learning_rate": 0.00019991774404333818,
      "loss": 2.3149,
      "step": 770
    },
    {
      "epoch": 0.33988779345280246,
      "grad_norm": 1.021190881729126,
      "learning_rate": 0.00019989589859645051,
      "loss": 2.2785,
      "step": 780
    },
    {
      "epoch": 0.3442453292662999,
      "grad_norm": 0.74828040599823,
      "learning_rate": 0.00019987148498023594,
      "loss": 2.2069,
      "step": 790
    },
    {
      "epoch": 0.3486028650797974,
      "grad_norm": 1.207062840461731,
      "learning_rate": 0.00019984450382233074,
      "loss": 2.279,
      "step": 800
    },
    {
      "epoch": 0.35296040089329483,
      "grad_norm": 0.7421720623970032,
      "learning_rate": 0.00019981495581637893,
      "loss": 2.3526,
      "step": 810
    },
    {
      "epoch": 0.3573179367067923,
      "grad_norm": 0.6931360960006714,
      "learning_rate": 0.00019978284172201405,
      "loss": 2.1866,
      "step": 820
    },
    {
      "epoch": 0.36167547252028975,
      "grad_norm": 0.6708277463912964,
      "learning_rate": 0.00019974816236483992,
      "loss": 2.3431,
      "step": 830
    },
    {
      "epoch": 0.36603300833378727,
      "grad_norm": 0.9695701599121094,
      "learning_rate": 0.00019971091863640926,
      "loss": 2.2229,
      "step": 840
    },
    {
      "epoch": 0.37039054414728473,
      "grad_norm": 0.8038255572319031,
      "learning_rate": 0.00019967111149420084,
      "loss": 2.2012,
      "step": 850
    },
    {
      "epoch": 0.3747480799607822,
      "grad_norm": 0.6550365090370178,
      "learning_rate": 0.00019962874196159485,
      "loss": 2.3334,
      "step": 860
    },
    {
      "epoch": 0.37910561577427965,
      "grad_norm": 2.6212825775146484,
      "learning_rate": 0.00019958381112784653,
      "loss": 2.3191,
      "step": 870
    },
    {
      "epoch": 0.3834631515877771,
      "grad_norm": 0.6571226119995117,
      "learning_rate": 0.00019953632014805823,
      "loss": 2.3411,
      "step": 880
    },
    {
      "epoch": 0.38782068740127457,
      "grad_norm": 0.5731409192085266,
      "learning_rate": 0.00019948627024314974,
      "loss": 2.272,
      "step": 890
    },
    {
      "epoch": 0.392178223214772,
      "grad_norm": 0.8394882082939148,
      "learning_rate": 0.00019943366269982687,
      "loss": 2.2741,
      "step": 900
    },
    {
      "epoch": 0.39653575902826954,
      "grad_norm": 0.6898312568664551,
      "learning_rate": 0.00019937849887054833,
      "loss": 2.3129,
      "step": 910
    },
    {
      "epoch": 0.400893294841767,
      "grad_norm": 0.6510561108589172,
      "learning_rate": 0.000199320780173491,
      "loss": 2.315,
      "step": 920
    },
    {
      "epoch": 0.40525083065526446,
      "grad_norm": 0.6493698954582214,
      "learning_rate": 0.00019926050809251344,
      "loss": 2.2978,
      "step": 930
    },
    {
      "epoch": 0.4096083664687619,
      "grad_norm": 0.6615191698074341,
      "learning_rate": 0.00019919768417711784,
      "loss": 2.2979,
      "step": 940
    },
    {
      "epoch": 0.4139659022822594,
      "grad_norm": 0.6701499223709106,
      "learning_rate": 0.00019913231004241007,
      "loss": 2.3705,
      "step": 950
    },
    {
      "epoch": 0.41832343809575684,
      "grad_norm": 0.857494592666626,
      "learning_rate": 0.00019906438736905818,
      "loss": 2.2945,
      "step": 960
    },
    {
      "epoch": 0.4226809739092543,
      "grad_norm": 0.8890170454978943,
      "learning_rate": 0.00019899391790324927,
      "loss": 2.2981,
      "step": 970
    },
    {
      "epoch": 0.42703850972275176,
      "grad_norm": 0.8094494938850403,
      "learning_rate": 0.00019892090345664446,
      "loss": 2.3287,
      "step": 980
    },
    {
      "epoch": 0.4313960455362493,
      "grad_norm": 0.5923323035240173,
      "learning_rate": 0.0001988453459063325,
      "loss": 2.2763,
      "step": 990
    },
    {
      "epoch": 0.43575358134974673,
      "grad_norm": 0.7998819947242737,
      "learning_rate": 0.00019876724719478136,
      "loss": 2.3202,
      "step": 1000
    },
    {
      "epoch": 0.43575358134974673,
      "eval_loss": NaN,
      "eval_runtime": 1040.815,
      "eval_samples_per_second": 3.613,
      "eval_steps_per_second": 3.613,
      "step": 1000
    },
    {
      "epoch": 0.4401111171632442,
      "grad_norm": 1.1197642087936401,
      "learning_rate": 0.0001986866093297883,
      "loss": 2.2908,
      "step": 1010
    },
    {
      "epoch": 0.44446865297674165,
      "grad_norm": 0.747607946395874,
      "learning_rate": 0.00019860343438442835,
      "loss": 2.3226,
      "step": 1020
    },
    {
      "epoch": 0.4488261887902391,
      "grad_norm": 0.7133992314338684,
      "learning_rate": 0.00019851772449700094,
      "loss": 2.3204,
      "step": 1030
    },
    {
      "epoch": 0.45318372460373657,
      "grad_norm": 0.6899197697639465,
      "learning_rate": 0.00019842948187097497,
      "loss": 2.3689,
      "step": 1040
    },
    {
      "epoch": 0.45754126041723403,
      "grad_norm": 0.9021736979484558,
      "learning_rate": 0.00019833870877493208,
      "loss": 2.3146,
      "step": 1050
    },
    {
      "epoch": 0.46189879623073155,
      "grad_norm": 0.985647976398468,
      "learning_rate": 0.0001982454075425085,
      "loss": 2.2571,
      "step": 1060
    },
    {
      "epoch": 0.466256332044229,
      "grad_norm": 0.8830334544181824,
      "learning_rate": 0.00019814958057233479,
      "loss": 2.4176,
      "step": 1070
    },
    {
      "epoch": 0.47061386785772646,
      "grad_norm": 0.8067160248756409,
      "learning_rate": 0.00019805123032797444,
      "loss": 2.3173,
      "step": 1080
    },
    {
      "epoch": 0.4749714036712239,
      "grad_norm": 0.7122374773025513,
      "learning_rate": 0.00019795035933786045,
      "loss": 2.2844,
      "step": 1090
    },
    {
      "epoch": 0.4793289394847214,
      "grad_norm": 1.5306648015975952,
      "learning_rate": 0.00019784697019523017,
      "loss": 2.3069,
      "step": 1100
    },
    {
      "epoch": 0.48368647529821884,
      "grad_norm": 0.8249468803405762,
      "learning_rate": 0.00019774106555805885,
      "loss": 2.3554,
      "step": 1110
    },
    {
      "epoch": 0.4880440111117163,
      "grad_norm": 1.0070773363113403,
      "learning_rate": 0.00019763264814899123,
      "loss": 2.2405,
      "step": 1120
    },
    {
      "epoch": 0.4924015469252138,
      "grad_norm": 0.9236782193183899,
      "learning_rate": 0.0001975217207552715,
      "loss": 2.329,
      "step": 1130
    },
    {
      "epoch": 0.4967590827387113,
      "grad_norm": 0.6689554452896118,
      "learning_rate": 0.00019740828622867172,
      "loss": 2.3,
      "step": 1140
    },
    {
      "epoch": 0.5011166185522087,
      "grad_norm": 0.7529979944229126,
      "learning_rate": 0.0001972923474854184,
      "loss": 2.1794,
      "step": 1150
    },
    {
      "epoch": 0.5054741543657062,
      "grad_norm": 1.0750017166137695,
      "learning_rate": 0.00019717390750611768,
      "loss": 2.1769,
      "step": 1160
    },
    {
      "epoch": 0.5098316901792037,
      "grad_norm": 0.8313055634498596,
      "learning_rate": 0.00019705296933567853,
      "loss": 2.313,
      "step": 1170
    },
    {
      "epoch": 0.5141892259927011,
      "grad_norm": 0.6539650559425354,
      "learning_rate": 0.00019692953608323462,
      "loss": 2.3325,
      "step": 1180
    },
    {
      "epoch": 0.5185467618061986,
      "grad_norm": 0.8997268676757812,
      "learning_rate": 0.0001968036109220643,
      "loss": 2.1895,
      "step": 1190
    },
    {
      "epoch": 0.522904297619696,
      "grad_norm": 0.789900541305542,
      "learning_rate": 0.00019667519708950904,
      "loss": 2.1968,
      "step": 1200
    },
    {
      "epoch": 0.5272618334331935,
      "grad_norm": 0.8747245669364929,
      "learning_rate": 0.00019654429788689028,
      "loss": 2.3353,
      "step": 1210
    },
    {
      "epoch": 0.531619369246691,
      "grad_norm": 0.5671640634536743,
      "learning_rate": 0.0001964109166794244,
      "loss": 2.2604,
      "step": 1220
    },
    {
      "epoch": 0.5359769050601885,
      "grad_norm": 0.7236809730529785,
      "learning_rate": 0.00019627505689613625,
      "loss": 2.3113,
      "step": 1230
    },
    {
      "epoch": 0.540334440873686,
      "grad_norm": 0.799098789691925,
      "learning_rate": 0.0001961367220297712,
      "loss": 2.3304,
      "step": 1240
    },
    {
      "epoch": 0.5446919766871834,
      "grad_norm": 0.8223409056663513,
      "learning_rate": 0.00019599591563670504,
      "loss": 2.3668,
      "step": 1250
    },
    {
      "epoch": 0.5446919766871834,
      "eval_loss": NaN,
      "eval_runtime": 1032.1652,
      "eval_samples_per_second": 3.643,
      "eval_steps_per_second": 3.643,
      "step": 1250
    },
    {
      "epoch": 0.5490495125006809,
      "grad_norm": 0.9563683271408081,
      "learning_rate": 0.0001958526413368528,
      "loss": 2.3464,
      "step": 1260
    },
    {
      "epoch": 0.5534070483141783,
      "grad_norm": 1.3318967819213867,
      "learning_rate": 0.0001957069028135755,
      "loss": 2.1899,
      "step": 1270
    },
    {
      "epoch": 0.5577645841276758,
      "grad_norm": 0.8241556286811829,
      "learning_rate": 0.00019555870381358554,
      "loss": 2.2062,
      "step": 1280
    },
    {
      "epoch": 0.5621221199411732,
      "grad_norm": 0.8859296441078186,
      "learning_rate": 0.00019540804814685046,
      "loss": 2.2366,
      "step": 1290
    },
    {
      "epoch": 0.5664796557546707,
      "grad_norm": 0.6527111530303955,
      "learning_rate": 0.00019525493968649486,
      "loss": 2.144,
      "step": 1300
    },
    {
      "epoch": 0.5708371915681683,
      "grad_norm": 0.6969940066337585,
      "learning_rate": 0.00019509938236870084,
      "loss": 2.1314,
      "step": 1310
    },
    {
      "epoch": 0.5751947273816657,
      "grad_norm": 1.0977085828781128,
      "learning_rate": 0.00019494138019260693,
      "loss": 2.3072,
      "step": 1320
    },
    {
      "epoch": 0.5795522631951632,
      "grad_norm": 0.6771331429481506,
      "learning_rate": 0.0001947809372202051,
      "loss": 2.2027,
      "step": 1330
    },
    {
      "epoch": 0.5839097990086606,
      "grad_norm": 0.8812131285667419,
      "learning_rate": 0.00019461805757623648,
      "loss": 2.3029,
      "step": 1340
    },
    {
      "epoch": 0.5882673348221581,
      "grad_norm": 0.561085045337677,
      "learning_rate": 0.00019445274544808525,
      "loss": 2.251,
      "step": 1350
    },
    {
      "epoch": 0.5926248706356555,
      "grad_norm": 0.8529321551322937,
      "learning_rate": 0.000194285005085671,
      "loss": 2.263,
      "step": 1360
    },
    {
      "epoch": 0.596982406449153,
      "grad_norm": 2.544705390930176,
      "learning_rate": 0.00019411484080133953,
      "loss": 2.3076,
      "step": 1370
    },
    {
      "epoch": 0.6013399422626504,
      "grad_norm": 1.0334949493408203,
      "learning_rate": 0.0001939422569697518,
      "loss": 2.3012,
      "step": 1380
    },
    {
      "epoch": 0.6056974780761479,
      "grad_norm": 0.8403321504592896,
      "learning_rate": 0.00019376725802777172,
      "loss": 2.2699,
      "step": 1390
    },
    {
      "epoch": 0.6100550138896454,
      "grad_norm": 0.9007716178894043,
      "learning_rate": 0.0001935898484743519,
      "loss": 2.2925,
      "step": 1400
    },
    {
      "epoch": 0.6144125497031429,
      "grad_norm": 0.9155252575874329,
      "learning_rate": 0.0001934100328704181,
      "loss": 2.2394,
      "step": 1410
    },
    {
      "epoch": 0.6187700855166404,
      "grad_norm": 1.0894874334335327,
      "learning_rate": 0.0001932278158387518,
      "loss": 2.3048,
      "step": 1420
    },
    {
      "epoch": 0.6231276213301378,
      "grad_norm": 0.6822034120559692,
      "learning_rate": 0.00019304320206387166,
      "loss": 2.1991,
      "step": 1430
    },
    {
      "epoch": 0.6274851571436353,
      "grad_norm": 0.8059714436531067,
      "learning_rate": 0.00019285619629191275,
      "loss": 2.251,
      "step": 1440
    },
    {
      "epoch": 0.6318426929571327,
      "grad_norm": 0.8198080658912659,
      "learning_rate": 0.00019266680333050477,
      "loss": 2.2918,
      "step": 1450
    },
    {
      "epoch": 0.6362002287706302,
      "grad_norm": 1.1557762622833252,
      "learning_rate": 0.0001924750280486484,
      "loss": 2.2409,
      "step": 1460
    },
    {
      "epoch": 0.6405577645841277,
      "grad_norm": 0.9641059637069702,
      "learning_rate": 0.00019228087537658998,
      "loss": 2.1813,
      "step": 1470
    },
    {
      "epoch": 0.6449153003976251,
      "grad_norm": 1.2851139307022095,
      "learning_rate": 0.00019208435030569504,
      "loss": 2.2673,
      "step": 1480
    },
    {
      "epoch": 0.6492728362111226,
      "grad_norm": 1.0501890182495117,
      "learning_rate": 0.00019188545788831972,
      "loss": 2.3425,
      "step": 1490
    },
    {
      "epoch": 0.65363037202462,
      "grad_norm": 0.7679728865623474,
      "learning_rate": 0.00019168420323768096,
      "loss": 2.0819,
      "step": 1500
    },
    {
      "epoch": 0.65363037202462,
      "eval_loss": NaN,
      "eval_runtime": 1034.4389,
      "eval_samples_per_second": 3.635,
      "eval_steps_per_second": 3.635,
      "step": 1500
    },
    {
      "epoch": 0.6579879078381176,
      "grad_norm": 0.8243717551231384,
      "learning_rate": 0.00019148059152772522,
      "loss": 2.2301,
      "step": 1510
    },
    {
      "epoch": 0.662345443651615,
      "grad_norm": 0.7837507128715515,
      "learning_rate": 0.0001912746279929951,
      "loss": 2.3114,
      "step": 1520
    },
    {
      "epoch": 0.6667029794651125,
      "grad_norm": 0.8082309365272522,
      "learning_rate": 0.00019106631792849515,
      "loss": 2.2629,
      "step": 1530
    },
    {
      "epoch": 0.67106051527861,
      "grad_norm": 0.6829442381858826,
      "learning_rate": 0.00019085566668955556,
      "loss": 2.2298,
      "step": 1540
    },
    {
      "epoch": 0.6754180510921074,
      "grad_norm": 0.7189052104949951,
      "learning_rate": 0.00019064267969169443,
      "loss": 2.314,
      "step": 1550
    },
    {
      "epoch": 0.6797755869056049,
      "grad_norm": 0.8497246503829956,
      "learning_rate": 0.0001904273624104786,
      "loss": 2.2395,
      "step": 1560
    },
    {
      "epoch": 0.6841331227191023,
      "grad_norm": 0.909966766834259,
      "learning_rate": 0.00019020972038138307,
      "loss": 2.2926,
      "step": 1570
    },
    {
      "epoch": 0.6884906585325998,
      "grad_norm": 0.7601097226142883,
      "learning_rate": 0.00018998975919964827,
      "loss": 2.2821,
      "step": 1580
    },
    {
      "epoch": 0.6928481943460972,
      "grad_norm": 0.6022806167602539,
      "learning_rate": 0.00018976748452013671,
      "loss": 2.3454,
      "step": 1590
    },
    {
      "epoch": 0.6972057301595947,
      "grad_norm": 0.8948356509208679,
      "learning_rate": 0.00018954290205718715,
      "loss": 2.2691,
      "step": 1600
    },
    {
      "epoch": 0.7015632659730923,
      "grad_norm": 0.9330514669418335,
      "learning_rate": 0.00018931601758446798,
      "loss": 2.2592,
      "step": 1610
    },
    {
      "epoch": 0.7059208017865897,
      "grad_norm": 0.8471698760986328,
      "learning_rate": 0.00018908683693482877,
      "loss": 2.2702,
      "step": 1620
    },
    {
      "epoch": 0.7102783376000872,
      "grad_norm": 0.9475632309913635,
      "learning_rate": 0.00018885536600015022,
      "loss": 2.3357,
      "step": 1630
    },
    {
      "epoch": 0.7146358734135846,
      "grad_norm": 0.755869448184967,
      "learning_rate": 0.00018862161073119262,
      "loss": 2.1641,
      "step": 1640
    },
    {
      "epoch": 0.7189934092270821,
      "grad_norm": 138.41055297851562,
      "learning_rate": 0.0001883855771374431,
      "loss": 2.2852,
      "step": 1650
    },
    {
      "epoch": 0.7233509450405795,
      "grad_norm": 1.0709501504898071,
      "learning_rate": 0.0001881472712869609,
      "loss": 2.3223,
      "step": 1660
    },
    {
      "epoch": 0.727708480854077,
      "grad_norm": 0.6848531365394592,
      "learning_rate": 0.0001879066993062216,
      "loss": 2.2613,
      "step": 1670
    },
    {
      "epoch": 0.7320660166675745,
      "grad_norm": 1.017295241355896,
      "learning_rate": 0.00018766386737995938,
      "loss": 2.2611,
      "step": 1680
    },
    {
      "epoch": 0.7364235524810719,
      "grad_norm": 1.126147985458374,
      "learning_rate": 0.0001874187817510081,
      "loss": 2.2649,
      "step": 1690
    },
    {
      "epoch": 0.7407810882945695,
      "grad_norm": 0.7845912575721741,
      "learning_rate": 0.00018717144872014104,
      "loss": 2.201,
      "step": 1700
    },
    {
      "epoch": 0.7451386241080669,
      "grad_norm": 0.8803726434707642,
      "learning_rate": 0.00018692187464590846,
      "loss": 2.2579,
      "step": 1710
    },
    {
      "epoch": 0.7494961599215644,
      "grad_norm": 0.7140477895736694,
      "learning_rate": 0.0001866700659444745,
      "loss": 2.2686,
      "step": 1720
    },
    {
      "epoch": 0.7538536957350618,
      "grad_norm": 0.7175538539886475,
      "learning_rate": 0.00018641602908945216,
      "loss": 2.3485,
      "step": 1730
    },
    {
      "epoch": 0.7582112315485593,
      "grad_norm": 1.1032111644744873,
      "learning_rate": 0.0001861597706117368,
      "loss": 2.1876,
      "step": 1740
    },
    {
      "epoch": 0.7625687673620568,
      "grad_norm": 1.0922117233276367,
      "learning_rate": 0.0001859012970993382,
      "loss": 2.2863,
      "step": 1750
    },
    {
      "epoch": 0.7625687673620568,
      "eval_loss": NaN,
      "eval_runtime": 1048.2742,
      "eval_samples_per_second": 3.587,
      "eval_steps_per_second": 3.587,
      "step": 1750
    },
    {
      "epoch": 0.7669263031755542,
      "grad_norm": 0.6614721417427063,
      "learning_rate": 0.00018564061519721133,
      "loss": 2.2668,
      "step": 1760
    },
    {
      "epoch": 0.7712838389890517,
      "grad_norm": 0.7755153775215149,
      "learning_rate": 0.00018537773160708546,
      "loss": 2.1751,
      "step": 1770
    },
    {
      "epoch": 0.7756413748025491,
      "grad_norm": 1.5737738609313965,
      "learning_rate": 0.0001851126530872918,
      "loss": 2.2187,
      "step": 1780
    },
    {
      "epoch": 0.7799989106160466,
      "grad_norm": 0.771089494228363,
      "learning_rate": 0.0001848453864525899,
      "loss": 2.2942,
      "step": 1790
    },
    {
      "epoch": 0.784356446429544,
      "grad_norm": 0.7200314402580261,
      "learning_rate": 0.00018457593857399224,
      "loss": 2.3985,
      "step": 1800
    },
    {
      "epoch": 0.7887139822430416,
      "grad_norm": 1.0748608112335205,
      "learning_rate": 0.00018430431637858784,
      "loss": 2.2946,
      "step": 1810
    },
    {
      "epoch": 0.7930715180565391,
      "grad_norm": 0.7903848886489868,
      "learning_rate": 0.000184030526849364,
      "loss": 2.2909,
      "step": 1820
    },
    {
      "epoch": 0.7974290538700365,
      "grad_norm": 0.8104417324066162,
      "learning_rate": 0.0001837545770250268,
      "loss": 2.2641,
      "step": 1830
    },
    {
      "epoch": 0.801786589683534,
      "grad_norm": 1.0046426057815552,
      "learning_rate": 0.00018347647399982023,
      "loss": 2.3715,
      "step": 1840
    },
    {
      "epoch": 0.8061441254970314,
      "grad_norm": 0.861785352230072,
      "learning_rate": 0.00018319622492334362,
      "loss": 2.2412,
      "step": 1850
    },
    {
      "epoch": 0.8105016613105289,
      "grad_norm": 0.7005493640899658,
      "learning_rate": 0.00018291383700036817,
      "loss": 2.2274,
      "step": 1860
    },
    {
      "epoch": 0.8148591971240263,
      "grad_norm": 0.9184086322784424,
      "learning_rate": 0.00018262931749065135,
      "loss": 2.3448,
      "step": 1870
    },
    {
      "epoch": 0.8192167329375238,
      "grad_norm": 0.7390549778938293,
      "learning_rate": 0.00018234267370875049,
      "loss": 2.2537,
      "step": 1880
    },
    {
      "epoch": 0.8235742687510212,
      "grad_norm": 1.2159188985824585,
      "learning_rate": 0.00018205391302383473,
      "loss": 2.1902,
      "step": 1890
    },
    {
      "epoch": 0.8279318045645188,
      "grad_norm": 0.7919829487800598,
      "learning_rate": 0.00018176304285949543,
      "loss": 2.2043,
      "step": 1900
    },
    {
      "epoch": 0.8322893403780163,
      "grad_norm": 0.741897702217102,
      "learning_rate": 0.00018147007069355543,
      "loss": 2.1837,
      "step": 1910
    },
    {
      "epoch": 0.8366468761915137,
      "grad_norm": 0.8750457763671875,
      "learning_rate": 0.0001811750040578769,
      "loss": 2.3881,
      "step": 1920
    },
    {
      "epoch": 0.8410044120050112,
      "grad_norm": 0.8257079124450684,
      "learning_rate": 0.00018087785053816737,
      "loss": 2.2,
      "step": 1930
    },
    {
      "epoch": 0.8453619478185086,
      "grad_norm": 1.1117966175079346,
      "learning_rate": 0.0001805786177737852,
      "loss": 2.2968,
      "step": 1940
    },
    {
      "epoch": 0.8497194836320061,
      "grad_norm": 0.6271906495094299,
      "learning_rate": 0.00018027731345754267,
      "loss": 2.3083,
      "step": 1950
    },
    {
      "epoch": 0.8540770194455035,
      "grad_norm": 0.8071078062057495,
      "learning_rate": 0.00017997394533550865,
      "loss": 2.2714,
      "step": 1960
    },
    {
      "epoch": 0.858434555259001,
      "grad_norm": 0.8358751535415649,
      "learning_rate": 0.00017966852120680917,
      "loss": 2.2049,
      "step": 1970
    },
    {
      "epoch": 0.8627920910724985,
      "grad_norm": 1.0694124698638916,
      "learning_rate": 0.00017936104892342703,
      "loss": 2.2487,
      "step": 1980
    },
    {
      "epoch": 0.867149626885996,
      "grad_norm": 1.1254911422729492,
      "learning_rate": 0.00017905153639,
      "loss": 2.2333,
      "step": 1990
    },
    {
      "epoch": 0.8715071626994935,
      "grad_norm": 0.6726847290992737,
      "learning_rate": 0.00017873999156361737,
      "loss": 2.2865,
      "step": 2000
    },
    {
      "epoch": 0.8715071626994935,
      "eval_loss": NaN,
      "eval_runtime": 1062.6974,
      "eval_samples_per_second": 3.538,
      "eval_steps_per_second": 3.538,
      "step": 2000
    },
    {
      "epoch": 0.8758646985129909,
      "grad_norm": 0.8026793599128723,
      "learning_rate": 0.00017842642245361577,
      "loss": 2.2888,
      "step": 2010
    },
    {
      "epoch": 0.8802222343264884,
      "grad_norm": 1.1211217641830444,
      "learning_rate": 0.0001781108371213728,
      "loss": 2.2594,
      "step": 2020
    },
    {
      "epoch": 0.8845797701399858,
      "grad_norm": 0.6052644848823547,
      "learning_rate": 0.00017779324368010014,
      "loss": 2.3774,
      "step": 2030
    },
    {
      "epoch": 0.8889373059534833,
      "grad_norm": 0.8251080513000488,
      "learning_rate": 0.0001774736502946349,
      "loss": 2.3489,
      "step": 2040
    },
    {
      "epoch": 0.8932948417669808,
      "grad_norm": 1.0028810501098633,
      "learning_rate": 0.0001771520651812296,
      "loss": 2.2135,
      "step": 2050
    },
    {
      "epoch": 0.8976523775804782,
      "grad_norm": 1.1279181241989136,
      "learning_rate": 0.000176828496607341,
      "loss": 2.2375,
      "step": 2060
    },
    {
      "epoch": 0.9020099133939757,
      "grad_norm": 1.1033750772476196,
      "learning_rate": 0.00017650295289141758,
      "loss": 2.2111,
      "step": 2070
    },
    {
      "epoch": 0.9063674492074731,
      "grad_norm": 1.0076255798339844,
      "learning_rate": 0.0001761754424026857,
      "loss": 2.3189,
      "step": 2080
    },
    {
      "epoch": 0.9107249850209707,
      "grad_norm": 0.8165557980537415,
      "learning_rate": 0.0001758459735609344,
      "loss": 2.1202,
      "step": 2090
    },
    {
      "epoch": 0.9150825208344681,
      "grad_norm": 1.4226263761520386,
      "learning_rate": 0.0001755145548362989,
      "loss": 2.1429,
      "step": 2100
    },
    {
      "epoch": 0.9194400566479656,
      "grad_norm": 0.91651451587677,
      "learning_rate": 0.00017518119474904298,
      "loss": 2.2559,
      "step": 2110
    },
    {
      "epoch": 0.9237975924614631,
      "grad_norm": 0.7402326464653015,
      "learning_rate": 0.0001748459018693398,
      "loss": 2.3853,
      "step": 2120
    },
    {
      "epoch": 0.9281551282749605,
      "grad_norm": 1.159696340560913,
      "learning_rate": 0.0001745086848170517,
      "loss": 2.3836,
      "step": 2130
    },
    {
      "epoch": 0.932512664088458,
      "grad_norm": 0.8861343264579773,
      "learning_rate": 0.00017416955226150845,
      "loss": 2.3003,
      "step": 2140
    },
    {
      "epoch": 0.9368701999019554,
      "grad_norm": 1.0499920845031738,
      "learning_rate": 0.00017382851292128444,
      "loss": 2.1555,
      "step": 2150
    },
    {
      "epoch": 0.9412277357154529,
      "grad_norm": 0.595319390296936,
      "learning_rate": 0.00017348557556397462,
      "loss": 2.2693,
      "step": 2160
    },
    {
      "epoch": 0.9455852715289503,
      "grad_norm": 0.8581869602203369,
      "learning_rate": 0.00017314074900596897,
      "loss": 2.2642,
      "step": 2170
    },
    {
      "epoch": 0.9499428073424478,
      "grad_norm": 0.7796758413314819,
      "learning_rate": 0.00017279404211222602,
      "loss": 2.1567,
      "step": 2180
    },
    {
      "epoch": 0.9543003431559454,
      "grad_norm": 0.843284547328949,
      "learning_rate": 0.0001724454637960446,
      "loss": 2.2565,
      "step": 2190
    },
    {
      "epoch": 0.9586578789694428,
      "grad_norm": 0.7058560252189636,
      "learning_rate": 0.00017209502301883514,
      "loss": 2.2091,
      "step": 2200
    },
    {
      "epoch": 0.9630154147829403,
      "grad_norm": 0.7126532793045044,
      "learning_rate": 0.000171742728789889,
      "loss": 2.2738,
      "step": 2210
    },
    {
      "epoch": 0.9673729505964377,
      "grad_norm": 0.8627879023551941,
      "learning_rate": 0.0001713885901661469,
      "loss": 2.231,
      "step": 2220
    },
    {
      "epoch": 0.9717304864099352,
      "grad_norm": 0.9543893933296204,
      "learning_rate": 0.00017103261625196607,
      "loss": 2.3457,
      "step": 2230
    },
    {
      "epoch": 0.9760880222234326,
      "grad_norm": 0.8573060035705566,
      "learning_rate": 0.00017067481619888634,
      "loss": 2.2437,
      "step": 2240
    },
    {
      "epoch": 0.9804455580369301,
      "grad_norm": 0.7860355377197266,
      "learning_rate": 0.00017031519920539462,
      "loss": 2.2726,
      "step": 2250
    },
    {
      "epoch": 0.9804455580369301,
      "eval_loss": NaN,
      "eval_runtime": 1046.1678,
      "eval_samples_per_second": 3.594,
      "eval_steps_per_second": 3.594,
      "step": 2250
    },
    {
      "epoch": 0.9848030938504276,
      "grad_norm": 1.0169811248779297,
      "learning_rate": 0.00016995377451668864,
      "loss": 2.3181,
      "step": 2260
    },
    {
      "epoch": 0.989160629663925,
      "grad_norm": 0.8947784900665283,
      "learning_rate": 0.00016959055142443913,
      "loss": 2.1675,
      "step": 2270
    },
    {
      "epoch": 0.9935181654774226,
      "grad_norm": 1.0876487493515015,
      "learning_rate": 0.00016922553926655107,
      "loss": 2.2676,
      "step": 2280
    },
    {
      "epoch": 0.99787570129092,
      "grad_norm": 1.2884302139282227,
      "learning_rate": 0.00016885874742692344,
      "loss": 2.2222,
      "step": 2290
    },
    {
      "epoch": 1.0021787679067486,
      "grad_norm": 1.195877194404602,
      "learning_rate": 0.00016849018533520823,
      "loss": 2.1639,
      "step": 2300
    },
    {
      "epoch": 1.0065363037202462,
      "grad_norm": 1.023594856262207,
      "learning_rate": 0.00016811986246656778,
      "loss": 2.0131,
      "step": 2310
    },
    {
      "epoch": 1.0108938395337437,
      "grad_norm": 0.5998837947845459,
      "learning_rate": 0.0001677477883414313,
      "loss": 2.0534,
      "step": 2320
    },
    {
      "epoch": 1.0152513753472412,
      "grad_norm": 0.9317814111709595,
      "learning_rate": 0.00016737397252525012,
      "loss": 2.0921,
      "step": 2330
    },
    {
      "epoch": 1.0196089111607387,
      "grad_norm": 0.9385426640510559,
      "learning_rate": 0.00016699842462825177,
      "loss": 2.0874,
      "step": 2340
    },
    {
      "epoch": 1.023966446974236,
      "grad_norm": 1.0463721752166748,
      "learning_rate": 0.00016662115430519288,
      "loss": 1.966,
      "step": 2350
    },
    {
      "epoch": 1.0283239827877335,
      "grad_norm": 0.9932039380073547,
      "learning_rate": 0.00016624217125511093,
      "loss": 2.0481,
      "step": 2360
    },
    {
      "epoch": 1.032681518601231,
      "grad_norm": 0.8148595094680786,
      "learning_rate": 0.00016586148522107518,
      "loss": 2.0247,
      "step": 2370
    },
    {
      "epoch": 1.0370390544147285,
      "grad_norm": 1.1780062913894653,
      "learning_rate": 0.00016547910598993575,
      "loss": 2.0255,
      "step": 2380
    },
    {
      "epoch": 1.0413965902282258,
      "grad_norm": 0.9054592251777649,
      "learning_rate": 0.0001650950433920723,
      "loss": 2.0283,
      "step": 2390
    },
    {
      "epoch": 1.0457541260417234,
      "grad_norm": 0.799586832523346,
      "learning_rate": 0.00016470930730114135,
      "loss": 1.9901,
      "step": 2400
    },
    {
      "epoch": 1.0501116618552209,
      "grad_norm": 1.5839719772338867,
      "learning_rate": 0.0001643219076338222,
      "loss": 1.9765,
      "step": 2410
    },
    {
      "epoch": 1.0544691976687184,
      "grad_norm": 1.0684462785720825,
      "learning_rate": 0.00016393285434956228,
      "loss": 1.9778,
      "step": 2420
    },
    {
      "epoch": 1.058826733482216,
      "grad_norm": 0.9332830905914307,
      "learning_rate": 0.00016354215745032082,
      "loss": 2.0527,
      "step": 2430
    },
    {
      "epoch": 1.0631842692957132,
      "grad_norm": 1.357889175415039,
      "learning_rate": 0.00016314982698031197,
      "loss": 2.0278,
      "step": 2440
    },
    {
      "epoch": 1.0675418051092107,
      "grad_norm": 1.3411509990692139,
      "learning_rate": 0.00016275587302574634,
      "loss": 1.9699,
      "step": 2450
    },
    {
      "epoch": 1.0718993409227082,
      "grad_norm": 1.209087610244751,
      "learning_rate": 0.00016236030571457194,
      "loss": 1.9948,
      "step": 2460
    },
    {
      "epoch": 1.0762568767362057,
      "grad_norm": 1.0245816707611084,
      "learning_rate": 0.00016196313521621365,
      "loss": 2.1152,
      "step": 2470
    },
    {
      "epoch": 1.080614412549703,
      "grad_norm": 1.1089764833450317,
      "learning_rate": 0.00016156437174131178,
      "loss": 2.1335,
      "step": 2480
    },
    {
      "epoch": 1.0849719483632005,
      "grad_norm": 1.0113691091537476,
      "learning_rate": 0.00016116402554145962,
      "loss": 1.9845,
      "step": 2490
    },
    {
      "epoch": 1.089329484176698,
      "grad_norm": 0.8839043378829956,
      "learning_rate": 0.00016076210690893987,
      "loss": 2.0197,
      "step": 2500
    },
    {
      "epoch": 1.089329484176698,
      "eval_loss": NaN,
      "eval_runtime": 1046.5306,
      "eval_samples_per_second": 3.593,
      "eval_steps_per_second": 3.593,
      "step": 2500
    },
    {
      "epoch": 1.0936870199901956,
      "grad_norm": 0.9823530316352844,
      "learning_rate": 0.00016035862617646011,
      "loss": 2.0136,
      "step": 2510
    },
    {
      "epoch": 1.098044555803693,
      "grad_norm": 0.9081467986106873,
      "learning_rate": 0.00015995359371688705,
      "loss": 1.9843,
      "step": 2520
    },
    {
      "epoch": 1.1024020916171904,
      "grad_norm": 0.8609516620635986,
      "learning_rate": 0.00015954701994297987,
      "loss": 1.9976,
      "step": 2530
    },
    {
      "epoch": 1.106759627430688,
      "grad_norm": 0.8284578323364258,
      "learning_rate": 0.00015913891530712265,
      "loss": 2.0112,
      "step": 2540
    },
    {
      "epoch": 1.1111171632441854,
      "grad_norm": 0.854587733745575,
      "learning_rate": 0.0001587292903010555,
      "loss": 1.9897,
      "step": 2550
    },
    {
      "epoch": 1.115474699057683,
      "grad_norm": 1.2862526178359985,
      "learning_rate": 0.0001583181554556049,
      "loss": 2.0074,
      "step": 2560
    },
    {
      "epoch": 1.1198322348711804,
      "grad_norm": 0.9319202899932861,
      "learning_rate": 0.000157905521340413,
      "loss": 2.0124,
      "step": 2570
    },
    {
      "epoch": 1.1241897706846777,
      "grad_norm": 1.0119227170944214,
      "learning_rate": 0.00015749139856366582,
      "loss": 2.0487,
      "step": 2580
    },
    {
      "epoch": 1.1285473064981753,
      "grad_norm": 1.223533272743225,
      "learning_rate": 0.00015707579777182065,
      "loss": 1.9732,
      "step": 2590
    },
    {
      "epoch": 1.1329048423116728,
      "grad_norm": 0.7415319681167603,
      "learning_rate": 0.00015665872964933222,
      "loss": 1.9979,
      "step": 2600
    },
    {
      "epoch": 1.1372623781251703,
      "grad_norm": 0.9701756834983826,
      "learning_rate": 0.00015624020491837804,
      "loss": 2.0253,
      "step": 2610
    },
    {
      "epoch": 1.1416199139386678,
      "grad_norm": 0.7390375137329102,
      "learning_rate": 0.00015582023433858278,
      "loss": 2.0295,
      "step": 2620
    },
    {
      "epoch": 1.145977449752165,
      "grad_norm": 1.1096532344818115,
      "learning_rate": 0.00015539882870674166,
      "loss": 2.0106,
      "step": 2630
    },
    {
      "epoch": 1.1503349855656626,
      "grad_norm": 0.920838475227356,
      "learning_rate": 0.00015497599885654295,
      "loss": 2.0056,
      "step": 2640
    },
    {
      "epoch": 1.1546925213791601,
      "grad_norm": 0.877077043056488,
      "learning_rate": 0.0001545517556582892,
      "loss": 2.0444,
      "step": 2650
    },
    {
      "epoch": 1.1590500571926576,
      "grad_norm": 0.8202382326126099,
      "learning_rate": 0.00015412611001861817,
      "loss": 2.0103,
      "step": 2660
    },
    {
      "epoch": 1.163407593006155,
      "grad_norm": 1.1750988960266113,
      "learning_rate": 0.00015369907288022205,
      "loss": 2.0787,
      "step": 2670
    },
    {
      "epoch": 1.1677651288196524,
      "grad_norm": 0.9228484034538269,
      "learning_rate": 0.0001532706552215664,
      "loss": 2.1102,
      "step": 2680
    },
    {
      "epoch": 1.17212266463315,
      "grad_norm": 0.9391607046127319,
      "learning_rate": 0.0001528408680566078,
      "loss": 1.9857,
      "step": 2690
    },
    {
      "epoch": 1.1764802004466475,
      "grad_norm": 0.7933950424194336,
      "learning_rate": 0.00015240972243451073,
      "loss": 2.1278,
      "step": 2700
    },
    {
      "epoch": 1.1808377362601448,
      "grad_norm": 1.256343126296997,
      "learning_rate": 0.00015197722943936348,
      "loss": 2.0598,
      "step": 2710
    },
    {
      "epoch": 1.1851952720736423,
      "grad_norm": 1.2324795722961426,
      "learning_rate": 0.0001515434001898933,
      "loss": 1.9666,
      "step": 2720
    },
    {
      "epoch": 1.1895528078871398,
      "grad_norm": 0.8166870474815369,
      "learning_rate": 0.00015110824583918034,
      "loss": 2.0142,
      "step": 2730
    },
    {
      "epoch": 1.1939103437006373,
      "grad_norm": 1.055680274963379,
      "learning_rate": 0.00015067177757437122,
      "loss": 2.0609,
      "step": 2740
    },
    {
      "epoch": 1.1982678795141348,
      "grad_norm": 0.8803584575653076,
      "learning_rate": 0.00015023400661639112,
      "loss": 2.0453,
      "step": 2750
    },
    {
      "epoch": 1.1982678795141348,
      "eval_loss": NaN,
      "eval_runtime": 1051.6004,
      "eval_samples_per_second": 3.576,
      "eval_steps_per_second": 3.576,
      "step": 2750
    },
    {
      "epoch": 1.2026254153276321,
      "grad_norm": 1.28597092628479,
      "learning_rate": 0.00014979494421965553,
      "loss": 2.1356,
      "step": 2760
    },
    {
      "epoch": 1.2069829511411296,
      "grad_norm": 0.9695041179656982,
      "learning_rate": 0.00014935460167178085,
      "loss": 2.0509,
      "step": 2770
    },
    {
      "epoch": 1.2113404869546271,
      "grad_norm": 1.2674109935760498,
      "learning_rate": 0.00014891299029329408,
      "loss": 2.0031,
      "step": 2780
    },
    {
      "epoch": 1.2156980227681247,
      "grad_norm": 1.0019211769104004,
      "learning_rate": 0.000148470121437342,
      "loss": 1.9638,
      "step": 2790
    },
    {
      "epoch": 1.2200555585816222,
      "grad_norm": 0.97481369972229,
      "learning_rate": 0.00014802600648939918,
      "loss": 2.1689,
      "step": 2800
    },
    {
      "epoch": 1.2244130943951195,
      "grad_norm": 0.9544556736946106,
      "learning_rate": 0.00014758065686697533,
      "loss": 2.033,
      "step": 2810
    },
    {
      "epoch": 1.228770630208617,
      "grad_norm": 0.8323889374732971,
      "learning_rate": 0.00014713408401932155,
      "loss": 2.0132,
      "step": 2820
    },
    {
      "epoch": 1.2331281660221145,
      "grad_norm": 0.9626023769378662,
      "learning_rate": 0.00014668629942713644,
      "loss": 2.0273,
      "step": 2830
    },
    {
      "epoch": 1.237485701835612,
      "grad_norm": 1.020627498626709,
      "learning_rate": 0.0001462373146022705,
      "loss": 2.0136,
      "step": 2840
    },
    {
      "epoch": 1.2418432376491095,
      "grad_norm": 1.0349328517913818,
      "learning_rate": 0.00014578714108743035,
      "loss": 1.966,
      "step": 2850
    },
    {
      "epoch": 1.2462007734626068,
      "grad_norm": 1.493476390838623,
      "learning_rate": 0.00014533579045588208,
      "loss": 2.0516,
      "step": 2860
    },
    {
      "epoch": 1.2505583092761043,
      "grad_norm": 1.0708987712860107,
      "learning_rate": 0.00014488327431115365,
      "loss": 1.9706,
      "step": 2870
    },
    {
      "epoch": 1.2549158450896019,
      "grad_norm": 0.9468846917152405,
      "learning_rate": 0.00014442960428673644,
      "loss": 1.9337,
      "step": 2880
    },
    {
      "epoch": 1.2592733809030994,
      "grad_norm": 0.7481556534767151,
      "learning_rate": 0.00014397479204578643,
      "loss": 1.9206,
      "step": 2890
    },
    {
      "epoch": 1.2636309167165969,
      "grad_norm": 0.8472184538841248,
      "learning_rate": 0.00014351884928082416,
      "loss": 1.9607,
      "step": 2900
    },
    {
      "epoch": 1.2679884525300942,
      "grad_norm": 1.025887370109558,
      "learning_rate": 0.00014306178771343419,
      "loss": 2.0654,
      "step": 2910
    },
    {
      "epoch": 1.2723459883435917,
      "grad_norm": 1.3405323028564453,
      "learning_rate": 0.00014260361909396375,
      "loss": 2.0386,
      "step": 2920
    },
    {
      "epoch": 1.2767035241570892,
      "grad_norm": 0.9046556353569031,
      "learning_rate": 0.0001421443552012207,
      "loss": 1.8927,
      "step": 2930
    },
    {
      "epoch": 1.2810610599705865,
      "grad_norm": 0.8600054979324341,
      "learning_rate": 0.00014168400784217075,
      "loss": 2.0339,
      "step": 2940
    },
    {
      "epoch": 1.2854185957840842,
      "grad_norm": 1.3467826843261719,
      "learning_rate": 0.0001412225888516337,
      "loss": 1.9831,
      "step": 2950
    },
    {
      "epoch": 1.2897761315975815,
      "grad_norm": 3.1968512535095215,
      "learning_rate": 0.00014076011009197948,
      "loss": 1.9848,
      "step": 2960
    },
    {
      "epoch": 1.294133667411079,
      "grad_norm": 1.055221438407898,
      "learning_rate": 0.00014029658345282296,
      "loss": 2.0128,
      "step": 2970
    },
    {
      "epoch": 1.2984912032245766,
      "grad_norm": 1.1931387186050415,
      "learning_rate": 0.00013983202085071842,
      "loss": 1.9943,
      "step": 2980
    },
    {
      "epoch": 1.3028487390380739,
      "grad_norm": 1.0042332410812378,
      "learning_rate": 0.00013936643422885316,
      "loss": 1.9502,
      "step": 2990
    },
    {
      "epoch": 1.3072062748515714,
      "grad_norm": 0.9566105604171753,
      "learning_rate": 0.00013889983555674041,
      "loss": 2.1049,
      "step": 3000
    },
    {
      "epoch": 1.3072062748515714,
      "eval_loss": NaN,
      "eval_runtime": 1048.3442,
      "eval_samples_per_second": 3.587,
      "eval_steps_per_second": 3.587,
      "step": 3000
    },
    {
      "epoch": 1.3115638106650689,
      "grad_norm": 0.8763812780380249,
      "learning_rate": 0.00013843223682991166,
      "loss": 2.0293,
      "step": 3010
    },
    {
      "epoch": 1.3159213464785664,
      "grad_norm": 0.7904341220855713,
      "learning_rate": 0.00013796365006960829,
      "loss": 1.9748,
      "step": 3020
    },
    {
      "epoch": 1.320278882292064,
      "grad_norm": 0.8760731220245361,
      "learning_rate": 0.0001374940873224724,
      "loss": 1.9987,
      "step": 3030
    },
    {
      "epoch": 1.3246364181055612,
      "grad_norm": 0.8843801021575928,
      "learning_rate": 0.00013702356066023737,
      "loss": 1.9575,
      "step": 3040
    },
    {
      "epoch": 1.3289939539190587,
      "grad_norm": 0.9160627126693726,
      "learning_rate": 0.0001365520821794172,
      "loss": 2.0693,
      "step": 3050
    },
    {
      "epoch": 1.3333514897325562,
      "grad_norm": 1.3655813932418823,
      "learning_rate": 0.00013607966400099573,
      "loss": 1.9232,
      "step": 3060
    },
    {
      "epoch": 1.3377090255460538,
      "grad_norm": 0.8920828104019165,
      "learning_rate": 0.00013560631827011502,
      "loss": 1.9959,
      "step": 3070
    },
    {
      "epoch": 1.3420665613595513,
      "grad_norm": 1.0541125535964966,
      "learning_rate": 0.00013513205715576297,
      "loss": 1.934,
      "step": 3080
    },
    {
      "epoch": 1.3464240971730486,
      "grad_norm": 1.3781309127807617,
      "learning_rate": 0.00013465689285046065,
      "loss": 2.0714,
      "step": 3090
    },
    {
      "epoch": 1.350781632986546,
      "grad_norm": 1.2108445167541504,
      "learning_rate": 0.0001341808375699488,
      "loss": 1.9347,
      "step": 3100
    },
    {
      "epoch": 1.3551391688000436,
      "grad_norm": 1.303829312324524,
      "learning_rate": 0.00013370390355287368,
      "loss": 2.0506,
      "step": 3110
    },
    {
      "epoch": 1.359496704613541,
      "grad_norm": 0.9189248085021973,
      "learning_rate": 0.00013322610306047255,
      "loss": 2.0334,
      "step": 3120
    },
    {
      "epoch": 1.3638542404270386,
      "grad_norm": 1.178287386894226,
      "learning_rate": 0.0001327474483762584,
      "loss": 2.0334,
      "step": 3130
    },
    {
      "epoch": 1.368211776240536,
      "grad_norm": 1.2281291484832764,
      "learning_rate": 0.00013226795180570423,
      "loss": 2.0459,
      "step": 3140
    },
    {
      "epoch": 1.3725693120540334,
      "grad_norm": 1.3277243375778198,
      "learning_rate": 0.0001317876256759265,
      "loss": 2.0788,
      "step": 3150
    },
    {
      "epoch": 1.376926847867531,
      "grad_norm": 0.8504654765129089,
      "learning_rate": 0.00013130648233536856,
      "loss": 2.0895,
      "step": 3160
    },
    {
      "epoch": 1.3812843836810285,
      "grad_norm": 0.9046629071235657,
      "learning_rate": 0.0001308245341534828,
      "loss": 2.093,
      "step": 3170
    },
    {
      "epoch": 1.385641919494526,
      "grad_norm": 1.1596015691757202,
      "learning_rate": 0.00013034179352041297,
      "loss": 1.9328,
      "step": 3180
    },
    {
      "epoch": 1.3899994553080233,
      "grad_norm": 0.9915165901184082,
      "learning_rate": 0.00012985827284667535,
      "loss": 2.0022,
      "step": 3190
    },
    {
      "epoch": 1.3943569911215208,
      "grad_norm": 0.7931407690048218,
      "learning_rate": 0.00012937398456284007,
      "loss": 2.0217,
      "step": 3200
    },
    {
      "epoch": 1.3987145269350183,
      "grad_norm": 1.100766897201538,
      "learning_rate": 0.00012888894111921117,
      "loss": 1.9374,
      "step": 3210
    },
    {
      "epoch": 1.4030720627485156,
      "grad_norm": 1.0845946073532104,
      "learning_rate": 0.00012840315498550682,
      "loss": 1.9924,
      "step": 3220
    },
    {
      "epoch": 1.407429598562013,
      "grad_norm": 1.0519095659255981,
      "learning_rate": 0.00012791663865053846,
      "loss": 1.9351,
      "step": 3230
    },
    {
      "epoch": 1.4117871343755106,
      "grad_norm": 1.2452890872955322,
      "learning_rate": 0.00012742940462188998,
      "loss": 2.121,
      "step": 3240
    },
    {
      "epoch": 1.4161446701890081,
      "grad_norm": 1.4537795782089233,
      "learning_rate": 0.000126941465425596,
      "loss": 2.0382,
      "step": 3250
    },
    {
      "epoch": 1.4161446701890081,
      "eval_loss": NaN,
      "eval_runtime": 1044.0232,
      "eval_samples_per_second": 3.601,
      "eval_steps_per_second": 3.601,
      "step": 3250
    },
    {
      "epoch": 1.4205022060025057,
      "grad_norm": 1.3163926601409912,
      "learning_rate": 0.00012645283360581994,
      "loss": 1.9498,
      "step": 3260
    },
    {
      "epoch": 1.424859741816003,
      "grad_norm": 1.1268768310546875,
      "learning_rate": 0.00012596352172453154,
      "loss": 2.019,
      "step": 3270
    },
    {
      "epoch": 1.4292172776295005,
      "grad_norm": 1.0653878450393677,
      "learning_rate": 0.00012547354236118385,
      "loss": 2.0098,
      "step": 3280
    },
    {
      "epoch": 1.433574813442998,
      "grad_norm": 2.0421361923217773,
      "learning_rate": 0.0001249829081123898,
      "loss": 2.0088,
      "step": 3290
    },
    {
      "epoch": 1.4379323492564955,
      "grad_norm": 0.9651367664337158,
      "learning_rate": 0.00012449163159159848,
      "loss": 2.01,
      "step": 3300
    },
    {
      "epoch": 1.442289885069993,
      "grad_norm": 1.0238332748413086,
      "learning_rate": 0.00012399972542877073,
      "loss": 1.9378,
      "step": 3310
    },
    {
      "epoch": 1.4466474208834903,
      "grad_norm": 1.0016862154006958,
      "learning_rate": 0.0001235072022700546,
      "loss": 1.9544,
      "step": 3320
    },
    {
      "epoch": 1.4510049566969878,
      "grad_norm": 1.1990370750427246,
      "learning_rate": 0.0001230140747774601,
      "loss": 2.068,
      "step": 3330
    },
    {
      "epoch": 1.4553624925104853,
      "grad_norm": 1.1035449504852295,
      "learning_rate": 0.0001225203556285337,
      "loss": 2.0156,
      "step": 3340
    },
    {
      "epoch": 1.4597200283239828,
      "grad_norm": 1.2037560939788818,
      "learning_rate": 0.00012202605751603256,
      "loss": 1.9636,
      "step": 3350
    },
    {
      "epoch": 1.4640775641374804,
      "grad_norm": 0.9937413930892944,
      "learning_rate": 0.00012153119314759797,
      "loss": 2.0059,
      "step": 3360
    },
    {
      "epoch": 1.4684350999509777,
      "grad_norm": 0.9848079085350037,
      "learning_rate": 0.00012103577524542884,
      "loss": 2.0226,
      "step": 3370
    },
    {
      "epoch": 1.4727926357644752,
      "grad_norm": 0.961785614490509,
      "learning_rate": 0.00012053981654595458,
      "loss": 2.0858,
      "step": 3380
    },
    {
      "epoch": 1.4771501715779727,
      "grad_norm": 1.0532634258270264,
      "learning_rate": 0.00012004332979950769,
      "loss": 2.1072,
      "step": 3390
    },
    {
      "epoch": 1.4815077073914702,
      "grad_norm": 1.8306059837341309,
      "learning_rate": 0.00011954632776999587,
      "loss": 2.0761,
      "step": 3400
    },
    {
      "epoch": 1.4858652432049677,
      "grad_norm": 0.7971268892288208,
      "learning_rate": 0.00011904882323457402,
      "loss": 2.0131,
      "step": 3410
    },
    {
      "epoch": 1.490222779018465,
      "grad_norm": 1.0158636569976807,
      "learning_rate": 0.00011855082898331566,
      "loss": 1.9312,
      "step": 3420
    },
    {
      "epoch": 1.4945803148319625,
      "grad_norm": 1.2151081562042236,
      "learning_rate": 0.00011805235781888413,
      "loss": 1.9501,
      "step": 3430
    },
    {
      "epoch": 1.49893785064546,
      "grad_norm": 0.896931529045105,
      "learning_rate": 0.00011755342255620352,
      "loss": 1.9608,
      "step": 3440
    },
    {
      "epoch": 1.5032953864589573,
      "grad_norm": 0.9942107796669006,
      "learning_rate": 0.00011705403602212915,
      "loss": 2.0144,
      "step": 3450
    },
    {
      "epoch": 1.507652922272455,
      "grad_norm": 1.026832103729248,
      "learning_rate": 0.0001165542110551178,
      "loss": 1.9177,
      "step": 3460
    },
    {
      "epoch": 1.5120104580859524,
      "grad_norm": 1.0448576211929321,
      "learning_rate": 0.00011605396050489771,
      "loss": 1.9789,
      "step": 3470
    },
    {
      "epoch": 1.5163679938994499,
      "grad_norm": 1.1942658424377441,
      "learning_rate": 0.00011555329723213823,
      "loss": 1.9701,
      "step": 3480
    },
    {
      "epoch": 1.5207255297129474,
      "grad_norm": 1.079850196838379,
      "learning_rate": 0.00011505223410811914,
      "loss": 1.9211,
      "step": 3490
    },
    {
      "epoch": 1.5250830655264447,
      "grad_norm": 1.1759127378463745,
      "learning_rate": 0.00011455078401439978,
      "loss": 2.0227,
      "step": 3500
    },
    {
      "epoch": 1.5250830655264447,
      "eval_loss": NaN,
      "eval_runtime": 1046.1837,
      "eval_samples_per_second": 3.594,
      "eval_steps_per_second": 3.594,
      "step": 3500
    },
    {
      "epoch": 1.5294406013399424,
      "grad_norm": 1.4097644090652466,
      "learning_rate": 0.00011404895984248787,
      "loss": 1.8953,
      "step": 3510
    },
    {
      "epoch": 1.5337981371534397,
      "grad_norm": 0.9883896708488464,
      "learning_rate": 0.00011354677449350812,
      "loss": 2.0622,
      "step": 3520
    },
    {
      "epoch": 1.5381556729669372,
      "grad_norm": 1.1219390630722046,
      "learning_rate": 0.00011304424087787056,
      "loss": 1.949,
      "step": 3530
    },
    {
      "epoch": 1.5425132087804347,
      "grad_norm": 0.8569381833076477,
      "learning_rate": 0.0001125413719149386,
      "loss": 2.0187,
      "step": 3540
    },
    {
      "epoch": 1.546870744593932,
      "grad_norm": 1.8816359043121338,
      "learning_rate": 0.00011203818053269692,
      "loss": 2.0637,
      "step": 3550
    },
    {
      "epoch": 1.5512282804074295,
      "grad_norm": 0.968889594078064,
      "learning_rate": 0.0001115346796674191,
      "loss": 2.0362,
      "step": 3560
    },
    {
      "epoch": 1.555585816220927,
      "grad_norm": 0.9018668532371521,
      "learning_rate": 0.00011103088226333505,
      "loss": 2.1614,
      "step": 3570
    },
    {
      "epoch": 1.5599433520344246,
      "grad_norm": 1.6067694425582886,
      "learning_rate": 0.00011052680127229819,
      "loss": 2.0431,
      "step": 3580
    },
    {
      "epoch": 1.564300887847922,
      "grad_norm": 0.8634563088417053,
      "learning_rate": 0.00011002244965345261,
      "loss": 1.9767,
      "step": 3590
    },
    {
      "epoch": 1.5686584236614194,
      "grad_norm": 0.9624009728431702,
      "learning_rate": 0.00010951784037289978,
      "loss": 2.0635,
      "step": 3600
    },
    {
      "epoch": 1.573015959474917,
      "grad_norm": 1.364449143409729,
      "learning_rate": 0.00010901298640336526,
      "loss": 2.0029,
      "step": 3610
    },
    {
      "epoch": 1.5773734952884144,
      "grad_norm": 1.019741415977478,
      "learning_rate": 0.00010850790072386512,
      "loss": 2.0519,
      "step": 3620
    },
    {
      "epoch": 1.5817310311019117,
      "grad_norm": 1.230808973312378,
      "learning_rate": 0.00010800259631937246,
      "loss": 2.1244,
      "step": 3630
    },
    {
      "epoch": 1.5860885669154094,
      "grad_norm": 0.8494858741760254,
      "learning_rate": 0.00010749708618048333,
      "loss": 2.0563,
      "step": 3640
    },
    {
      "epoch": 1.5904461027289067,
      "grad_norm": 0.8931126594543457,
      "learning_rate": 0.00010699138330308305,
      "loss": 2.0363,
      "step": 3650
    },
    {
      "epoch": 1.5948036385424043,
      "grad_norm": 1.1811312437057495,
      "learning_rate": 0.0001064855006880118,
      "loss": 2.062,
      "step": 3660
    },
    {
      "epoch": 1.5991611743559018,
      "grad_norm": 1.1690815687179565,
      "learning_rate": 0.0001059794513407306,
      "loss": 2.1119,
      "step": 3670
    },
    {
      "epoch": 1.603518710169399,
      "grad_norm": 2.071469783782959,
      "learning_rate": 0.00010547324827098692,
      "loss": 1.9773,
      "step": 3680
    },
    {
      "epoch": 1.6078762459828968,
      "grad_norm": 0.7219648361206055,
      "learning_rate": 0.00010496690449248014,
      "loss": 1.9707,
      "step": 3690
    },
    {
      "epoch": 1.612233781796394,
      "grad_norm": 0.9470708966255188,
      "learning_rate": 0.00010446043302252711,
      "loss": 1.9205,
      "step": 3700
    },
    {
      "epoch": 1.6165913176098916,
      "grad_norm": 1.3660672903060913,
      "learning_rate": 0.00010395384688172738,
      "loss": 1.9227,
      "step": 3710
    },
    {
      "epoch": 1.6209488534233891,
      "grad_norm": 1.1823375225067139,
      "learning_rate": 0.00010344715909362854,
      "loss": 2.07,
      "step": 3720
    },
    {
      "epoch": 1.6253063892368864,
      "grad_norm": 1.2929502725601196,
      "learning_rate": 0.00010294038268439136,
      "loss": 2.0282,
      "step": 3730
    },
    {
      "epoch": 1.6296639250503842,
      "grad_norm": 0.902570903301239,
      "learning_rate": 0.00010243353068245492,
      "loss": 1.9972,
      "step": 3740
    },
    {
      "epoch": 1.6340214608638814,
      "grad_norm": 0.8097673058509827,
      "learning_rate": 0.00010192661611820169,
      "loss": 1.9568,
      "step": 3750
    },
    {
      "epoch": 1.6340214608638814,
      "eval_loss": NaN,
      "eval_runtime": 1049.4945,
      "eval_samples_per_second": 3.583,
      "eval_steps_per_second": 3.583,
      "step": 3750
    },
    {
      "epoch": 1.638378996677379,
      "grad_norm": 0.7182924747467041,
      "learning_rate": 0.00010141965202362248,
      "loss": 1.9243,
      "step": 3760
    },
    {
      "epoch": 1.6427365324908765,
      "grad_norm": 0.9651800990104675,
      "learning_rate": 0.00010091265143198152,
      "loss": 2.0729,
      "step": 3770
    },
    {
      "epoch": 1.6470940683043738,
      "grad_norm": 1.1800473928451538,
      "learning_rate": 0.00010040562737748125,
      "loss": 2.0341,
      "step": 3780
    },
    {
      "epoch": 1.6514516041178715,
      "grad_norm": 0.9797525405883789,
      "learning_rate": 9.989859289492732e-05,
      "loss": 2.0043,
      "step": 3790
    },
    {
      "epoch": 1.6558091399313688,
      "grad_norm": 1.0690715312957764,
      "learning_rate": 9.93915610193935e-05,
      "loss": 2.1466,
      "step": 3800
    },
    {
      "epoch": 1.6601666757448663,
      "grad_norm": 1.088021993637085,
      "learning_rate": 9.888454478588655e-05,
      "loss": 2.0028,
      "step": 3810
    },
    {
      "epoch": 1.6645242115583638,
      "grad_norm": 1.6965758800506592,
      "learning_rate": 9.837755722901104e-05,
      "loss": 2.0006,
      "step": 3820
    },
    {
      "epoch": 1.6688817473718611,
      "grad_norm": 1.2491179704666138,
      "learning_rate": 9.787061138263431e-05,
      "loss": 2.1258,
      "step": 3830
    },
    {
      "epoch": 1.6732392831853586,
      "grad_norm": 1.0437794923782349,
      "learning_rate": 9.736372027955148e-05,
      "loss": 1.986,
      "step": 3840
    },
    {
      "epoch": 1.6775968189988562,
      "grad_norm": 1.0217061042785645,
      "learning_rate": 9.685689695115015e-05,
      "loss": 2.0778,
      "step": 3850
    },
    {
      "epoch": 1.6819543548123537,
      "grad_norm": 1.184261679649353,
      "learning_rate": 9.63501544270757e-05,
      "loss": 2.0172,
      "step": 3860
    },
    {
      "epoch": 1.6863118906258512,
      "grad_norm": 0.8600487112998962,
      "learning_rate": 9.584350573489603e-05,
      "loss": 1.896,
      "step": 3870
    },
    {
      "epoch": 1.6906694264393485,
      "grad_norm": 1.053047776222229,
      "learning_rate": 9.533696389976689e-05,
      "loss": 1.9268,
      "step": 3880
    },
    {
      "epoch": 1.695026962252846,
      "grad_norm": 1.4675266742706299,
      "learning_rate": 9.483054194409673e-05,
      "loss": 1.9598,
      "step": 3890
    },
    {
      "epoch": 1.6993844980663435,
      "grad_norm": 1.4747428894042969,
      "learning_rate": 9.432425288721228e-05,
      "loss": 1.9022,
      "step": 3900
    },
    {
      "epoch": 1.7037420338798408,
      "grad_norm": 1.9301663637161255,
      "learning_rate": 9.381810974502347e-05,
      "loss": 2.0363,
      "step": 3910
    },
    {
      "epoch": 1.7080995696933385,
      "grad_norm": 1.24350106716156,
      "learning_rate": 9.33121255296891e-05,
      "loss": 1.9733,
      "step": 3920
    },
    {
      "epoch": 1.7124571055068358,
      "grad_norm": 1.4228620529174805,
      "learning_rate": 9.280631324928216e-05,
      "loss": 1.8666,
      "step": 3930
    },
    {
      "epoch": 1.7168146413203333,
      "grad_norm": 0.8915148973464966,
      "learning_rate": 9.230068590745553e-05,
      "loss": 2.0827,
      "step": 3940
    },
    {
      "epoch": 1.7211721771338309,
      "grad_norm": 3.145145893096924,
      "learning_rate": 9.179525650310748e-05,
      "loss": 1.9811,
      "step": 3950
    },
    {
      "epoch": 1.7255297129473282,
      "grad_norm": 1.4712671041488647,
      "learning_rate": 9.129003803004771e-05,
      "loss": 1.9425,
      "step": 3960
    },
    {
      "epoch": 1.729887248760826,
      "grad_norm": 0.9295014142990112,
      "learning_rate": 9.078504347666317e-05,
      "loss": 2.0304,
      "step": 3970
    },
    {
      "epoch": 1.7342447845743232,
      "grad_norm": 1.003040075302124,
      "learning_rate": 9.028028582558416e-05,
      "loss": 2.026,
      "step": 3980
    },
    {
      "epoch": 1.7386023203878207,
      "grad_norm": 0.9843830466270447,
      "learning_rate": 8.977577805335067e-05,
      "loss": 2.035,
      "step": 3990
    },
    {
      "epoch": 1.7429598562013182,
      "grad_norm": 1.0504701137542725,
      "learning_rate": 8.927153313007853e-05,
      "loss": 1.9232,
      "step": 4000
    },
    {
      "epoch": 1.7429598562013182,
      "eval_loss": NaN,
      "eval_runtime": 1088.9226,
      "eval_samples_per_second": 3.453,
      "eval_steps_per_second": 3.453,
      "step": 4000
    },
    {
      "epoch": 1.7473173920148155,
      "grad_norm": 1.0080368518829346,
      "learning_rate": 8.876756401912636e-05,
      "loss": 2.0309,
      "step": 4010
    },
    {
      "epoch": 1.7516749278283132,
      "grad_norm": 1.033835768699646,
      "learning_rate": 8.826388367676182e-05,
      "loss": 2.001,
      "step": 4020
    },
    {
      "epoch": 1.7560324636418105,
      "grad_norm": 0.8868551850318909,
      "learning_rate": 8.776050505182896e-05,
      "loss": 1.9201,
      "step": 4030
    },
    {
      "epoch": 1.760389999455308,
      "grad_norm": 0.8531748652458191,
      "learning_rate": 8.725744108541505e-05,
      "loss": 2.0374,
      "step": 4040
    },
    {
      "epoch": 1.7647475352688056,
      "grad_norm": 1.1420470476150513,
      "learning_rate": 8.675470471051808e-05,
      "loss": 2.1528,
      "step": 4050
    },
    {
      "epoch": 1.7691050710823029,
      "grad_norm": 0.9985010623931885,
      "learning_rate": 8.625230885171397e-05,
      "loss": 1.995,
      "step": 4060
    },
    {
      "epoch": 1.7734626068958004,
      "grad_norm": 0.9921373128890991,
      "learning_rate": 8.575026642482473e-05,
      "loss": 2.1177,
      "step": 4070
    },
    {
      "epoch": 1.777820142709298,
      "grad_norm": 0.8944199681282043,
      "learning_rate": 8.524859033658597e-05,
      "loss": 1.9755,
      "step": 4080
    },
    {
      "epoch": 1.7821776785227954,
      "grad_norm": 2.6936283111572266,
      "learning_rate": 8.474729348431547e-05,
      "loss": 1.9968,
      "step": 4090
    },
    {
      "epoch": 1.786535214336293,
      "grad_norm": 1.20258367061615,
      "learning_rate": 8.424638875558132e-05,
      "loss": 2.0197,
      "step": 4100
    },
    {
      "epoch": 1.7908927501497902,
      "grad_norm": 1.0505813360214233,
      "learning_rate": 8.374588902787082e-05,
      "loss": 1.8187,
      "step": 4110
    },
    {
      "epoch": 1.7952502859632877,
      "grad_norm": 0.8941124677658081,
      "learning_rate": 8.324580716825924e-05,
      "loss": 1.9837,
      "step": 4120
    },
    {
      "epoch": 1.7996078217767852,
      "grad_norm": 1.1198335886001587,
      "learning_rate": 8.274615603307907e-05,
      "loss": 2.0549,
      "step": 4130
    },
    {
      "epoch": 1.8039653575902825,
      "grad_norm": 0.882468044757843,
      "learning_rate": 8.224694846758968e-05,
      "loss": 2.073,
      "step": 4140
    },
    {
      "epoch": 1.8083228934037803,
      "grad_norm": 0.7860232591629028,
      "learning_rate": 8.174819730564683e-05,
      "loss": 1.9394,
      "step": 4150
    },
    {
      "epoch": 1.8126804292172776,
      "grad_norm": 1.1450952291488647,
      "learning_rate": 8.124991536937292e-05,
      "loss": 2.0847,
      "step": 4160
    },
    {
      "epoch": 1.817037965030775,
      "grad_norm": 1.424882411956787,
      "learning_rate": 8.07521154688272e-05,
      "loss": 2.0691,
      "step": 4170
    },
    {
      "epoch": 1.8213955008442726,
      "grad_norm": 0.9407846331596375,
      "learning_rate": 8.025481040167664e-05,
      "loss": 2.0045,
      "step": 4180
    },
    {
      "epoch": 1.82575303665777,
      "grad_norm": 0.9127366542816162,
      "learning_rate": 7.975801295286668e-05,
      "loss": 2.0827,
      "step": 4190
    },
    {
      "epoch": 1.8301105724712676,
      "grad_norm": 1.0031538009643555,
      "learning_rate": 7.926173589429278e-05,
      "loss": 2.003,
      "step": 4200
    },
    {
      "epoch": 1.834468108284765,
      "grad_norm": 0.8168705105781555,
      "learning_rate": 7.876599198447191e-05,
      "loss": 1.9083,
      "step": 4210
    },
    {
      "epoch": 1.8388256440982624,
      "grad_norm": 1.6664869785308838,
      "learning_rate": 7.827079396821467e-05,
      "loss": 1.9908,
      "step": 4220
    },
    {
      "epoch": 1.84318317991176,
      "grad_norm": 0.9847636222839355,
      "learning_rate": 7.777615457629746e-05,
      "loss": 2.0014,
      "step": 4230
    },
    {
      "epoch": 1.8475407157252572,
      "grad_norm": 1.0352505445480347,
      "learning_rate": 7.72820865251355e-05,
      "loss": 1.9651,
      "step": 4240
    },
    {
      "epoch": 1.851898251538755,
      "grad_norm": 1.4051852226257324,
      "learning_rate": 7.678860251645551e-05,
      "loss": 1.923,
      "step": 4250
    },
    {
      "epoch": 1.851898251538755,
      "eval_loss": NaN,
      "eval_runtime": 1118.7944,
      "eval_samples_per_second": 3.361,
      "eval_steps_per_second": 3.361,
      "step": 4250
    },
    {
      "epoch": 1.8562557873522523,
      "grad_norm": 0.966995894908905,
      "learning_rate": 7.62957152369695e-05,
      "loss": 1.9743,
      "step": 4260
    },
    {
      "epoch": 1.8606133231657498,
      "grad_norm": 1.055908441543579,
      "learning_rate": 7.580343735804852e-05,
      "loss": 2.0874,
      "step": 4270
    },
    {
      "epoch": 1.8649708589792473,
      "grad_norm": 1.1298010349273682,
      "learning_rate": 7.531178153539677e-05,
      "loss": 2.112,
      "step": 4280
    },
    {
      "epoch": 1.8693283947927446,
      "grad_norm": 0.9068736433982849,
      "learning_rate": 7.482076040872646e-05,
      "loss": 1.9948,
      "step": 4290
    },
    {
      "epoch": 1.8736859306062423,
      "grad_norm": 1.0738946199417114,
      "learning_rate": 7.433038660143259e-05,
      "loss": 1.9816,
      "step": 4300
    },
    {
      "epoch": 1.8780434664197396,
      "grad_norm": 1.092416524887085,
      "learning_rate": 7.384067272026876e-05,
      "loss": 1.9445,
      "step": 4310
    },
    {
      "epoch": 1.8824010022332371,
      "grad_norm": 1.0050482749938965,
      "learning_rate": 7.335163135502277e-05,
      "loss": 2.0502,
      "step": 4320
    },
    {
      "epoch": 1.8867585380467347,
      "grad_norm": 1.130457878112793,
      "learning_rate": 7.286327507819313e-05,
      "loss": 2.0124,
      "step": 4330
    },
    {
      "epoch": 1.891116073860232,
      "grad_norm": 1.1905975341796875,
      "learning_rate": 7.237561644466571e-05,
      "loss": 1.9657,
      "step": 4340
    },
    {
      "epoch": 1.8954736096737295,
      "grad_norm": 1.1915481090545654,
      "learning_rate": 7.188866799139118e-05,
      "loss": 2.0148,
      "step": 4350
    },
    {
      "epoch": 1.899831145487227,
      "grad_norm": 1.00014066696167,
      "learning_rate": 7.140244223706238e-05,
      "loss": 1.9942,
      "step": 4360
    },
    {
      "epoch": 1.9041886813007245,
      "grad_norm": 1.4962925910949707,
      "learning_rate": 7.091695168179287e-05,
      "loss": 2.0182,
      "step": 4370
    },
    {
      "epoch": 1.908546217114222,
      "grad_norm": 1.11307954788208,
      "learning_rate": 7.043220880679524e-05,
      "loss": 2.1464,
      "step": 4380
    },
    {
      "epoch": 1.9129037529277193,
      "grad_norm": 1.0921409130096436,
      "learning_rate": 6.99482260740605e-05,
      "loss": 1.9972,
      "step": 4390
    },
    {
      "epoch": 1.9172612887412168,
      "grad_norm": 1.3979216814041138,
      "learning_rate": 6.946501592603748e-05,
      "loss": 1.9757,
      "step": 4400
    },
    {
      "epoch": 1.9216188245547143,
      "grad_norm": 0.7990900278091431,
      "learning_rate": 6.898259078531299e-05,
      "loss": 2.0252,
      "step": 4410
    },
    {
      "epoch": 1.9259763603682116,
      "grad_norm": 1.1722279787063599,
      "learning_rate": 6.85009630542927e-05,
      "loss": 2.0262,
      "step": 4420
    },
    {
      "epoch": 1.9303338961817094,
      "grad_norm": 0.837175190448761,
      "learning_rate": 6.802014511488193e-05,
      "loss": 1.9224,
      "step": 4430
    },
    {
      "epoch": 1.9346914319952067,
      "grad_norm": 1.0074602365493774,
      "learning_rate": 6.754014932816766e-05,
      "loss": 2.0773,
      "step": 4440
    },
    {
      "epoch": 1.9390489678087042,
      "grad_norm": 1.530935525894165,
      "learning_rate": 6.706098803410043e-05,
      "loss": 1.9472,
      "step": 4450
    },
    {
      "epoch": 1.9434065036222017,
      "grad_norm": 0.953169047832489,
      "learning_rate": 6.658267355117746e-05,
      "loss": 1.9851,
      "step": 4460
    },
    {
      "epoch": 1.947764039435699,
      "grad_norm": 1.298912763595581,
      "learning_rate": 6.610521817612553e-05,
      "loss": 2.0698,
      "step": 4470
    },
    {
      "epoch": 1.9521215752491967,
      "grad_norm": 0.8918735980987549,
      "learning_rate": 6.562863418358527e-05,
      "loss": 1.9482,
      "step": 4480
    },
    {
      "epoch": 1.956479111062694,
      "grad_norm": 0.8740583062171936,
      "learning_rate": 6.515293382579535e-05,
      "loss": 1.9668,
      "step": 4490
    },
    {
      "epoch": 1.9608366468761915,
      "grad_norm": 1.136130928993225,
      "learning_rate": 6.467812933227756e-05,
      "loss": 1.9575,
      "step": 4500
    },
    {
      "epoch": 1.9608366468761915,
      "eval_loss": NaN,
      "eval_runtime": 1633.9548,
      "eval_samples_per_second": 2.301,
      "eval_steps_per_second": 2.301,
      "step": 4500
    },
    {
      "epoch": 1.965194182689689,
      "grad_norm": 1.7607654333114624,
      "learning_rate": 6.420423290952233e-05,
      "loss": 1.9615,
      "step": 4510
    },
    {
      "epoch": 1.9695517185031863,
      "grad_norm": 0.8850117325782776,
      "learning_rate": 6.373125674067515e-05,
      "loss": 1.9607,
      "step": 4520
    },
    {
      "epoch": 1.973909254316684,
      "grad_norm": 0.9829928278923035,
      "learning_rate": 6.325921298522304e-05,
      "loss": 2.0133,
      "step": 4530
    },
    {
      "epoch": 1.9782667901301814,
      "grad_norm": 1.04380464553833,
      "learning_rate": 6.278811377868216e-05,
      "loss": 2.0886,
      "step": 4540
    },
    {
      "epoch": 1.9826243259436789,
      "grad_norm": 0.9099815487861633,
      "learning_rate": 6.231797123228589e-05,
      "loss": 2.0286,
      "step": 4550
    },
    {
      "epoch": 1.9869818617571764,
      "grad_norm": 1.0890592336654663,
      "learning_rate": 6.184879743267315e-05,
      "loss": 1.9131,
      "step": 4560
    },
    {
      "epoch": 1.9913393975706737,
      "grad_norm": 1.5321694612503052,
      "learning_rate": 6.138060444157807e-05,
      "loss": 2.0359,
      "step": 4570
    },
    {
      "epoch": 1.9956969333841712,
      "grad_norm": 1.4515916109085083,
      "learning_rate": 6.091340429551959e-05,
      "loss": 1.9727,
      "step": 4580
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.5934542417526245,
      "learning_rate": 6.0447209005492186e-05,
      "loss": 2.0833,
      "step": 4590
    },
    {
      "epoch": 2.0043575358134973,
      "grad_norm": 0.7665562033653259,
      "learning_rate": 5.998203055665698e-05,
      "loss": 1.7262,
      "step": 4600
    },
    {
      "epoch": 2.008715071626995,
      "grad_norm": 1.025671124458313,
      "learning_rate": 5.951788090803379e-05,
      "loss": 1.6918,
      "step": 4610
    },
    {
      "epoch": 2.0130726074404923,
      "grad_norm": 1.3751482963562012,
      "learning_rate": 5.9054771992193405e-05,
      "loss": 1.701,
      "step": 4620
    },
    {
      "epoch": 2.01743014325399,
      "grad_norm": 1.2799595594406128,
      "learning_rate": 5.859271571495115e-05,
      "loss": 1.6227,
      "step": 4630
    },
    {
      "epoch": 2.0217876790674874,
      "grad_norm": 1.131247878074646,
      "learning_rate": 5.813172395506052e-05,
      "loss": 1.5816,
      "step": 4640
    },
    {
      "epoch": 2.0261452148809846,
      "grad_norm": 1.1752917766571045,
      "learning_rate": 5.767180856390797e-05,
      "loss": 1.6963,
      "step": 4650
    },
    {
      "epoch": 2.0305027506944824,
      "grad_norm": 1.7277512550354004,
      "learning_rate": 5.721298136520816e-05,
      "loss": 1.5513,
      "step": 4660
    },
    {
      "epoch": 2.0348602865079797,
      "grad_norm": 0.7851143479347229,
      "learning_rate": 5.675525415469998e-05,
      "loss": 1.5871,
      "step": 4670
    },
    {
      "epoch": 2.0392178223214774,
      "grad_norm": 2.0114705562591553,
      "learning_rate": 5.6298638699843355e-05,
      "loss": 1.6629,
      "step": 4680
    },
    {
      "epoch": 2.0435753581349747,
      "grad_norm": 0.9911689162254333,
      "learning_rate": 5.5843146739516683e-05,
      "loss": 1.7438,
      "step": 4690
    },
    {
      "epoch": 2.047932893948472,
      "grad_norm": 0.958067774772644,
      "learning_rate": 5.538878998371504e-05,
      "loss": 1.6409,
      "step": 4700
    },
    {
      "epoch": 2.0522904297619697,
      "grad_norm": 1.0282528400421143,
      "learning_rate": 5.493558011324913e-05,
      "loss": 1.7565,
      "step": 4710
    },
    {
      "epoch": 2.056647965575467,
      "grad_norm": 1.4451402425765991,
      "learning_rate": 5.448352877944507e-05,
      "loss": 1.6826,
      "step": 4720
    },
    {
      "epoch": 2.0610055013889643,
      "grad_norm": 1.3234580755233765,
      "learning_rate": 5.403264760384467e-05,
      "loss": 1.6012,
      "step": 4730
    },
    {
      "epoch": 2.065363037202462,
      "grad_norm": 2.6169230937957764,
      "learning_rate": 5.3582948177906975e-05,
      "loss": 1.7503,
      "step": 4740
    },
    {
      "epoch": 2.0697205730159594,
      "grad_norm": 1.2050081491470337,
      "learning_rate": 5.313444206270981e-05,
      "loss": 1.7843,
      "step": 4750
    },
    {
      "epoch": 2.0697205730159594,
      "eval_loss": NaN,
      "eval_runtime": 1044.4395,
      "eval_samples_per_second": 3.6,
      "eval_steps_per_second": 3.6,
      "step": 4750
    },
    {
      "epoch": 2.074078108829457,
      "grad_norm": 2.155972719192505,
      "learning_rate": 5.2687140788653114e-05,
      "loss": 1.5807,
      "step": 4760
    },
    {
      "epoch": 2.0784356446429544,
      "grad_norm": 0.8957833647727966,
      "learning_rate": 5.22410558551619e-05,
      "loss": 1.7162,
      "step": 4770
    },
    {
      "epoch": 2.0827931804564517,
      "grad_norm": 0.9793320298194885,
      "learning_rate": 5.179619873039126e-05,
      "loss": 1.6567,
      "step": 4780
    },
    {
      "epoch": 2.0871507162699494,
      "grad_norm": 1.0934149026870728,
      "learning_rate": 5.1352580850930985e-05,
      "loss": 1.6213,
      "step": 4790
    },
    {
      "epoch": 2.0915082520834467,
      "grad_norm": 1.3025189638137817,
      "learning_rate": 5.091021362151192e-05,
      "loss": 1.8139,
      "step": 4800
    },
    {
      "epoch": 2.0958657878969444,
      "grad_norm": 1.2429715394973755,
      "learning_rate": 5.046910841471253e-05,
      "loss": 1.7248,
      "step": 4810
    },
    {
      "epoch": 2.1002233237104417,
      "grad_norm": 1.2477396726608276,
      "learning_rate": 5.002927657066672e-05,
      "loss": 1.7241,
      "step": 4820
    },
    {
      "epoch": 2.104580859523939,
      "grad_norm": 0.8730597496032715,
      "learning_rate": 4.959072939677212e-05,
      "loss": 1.6762,
      "step": 4830
    },
    {
      "epoch": 2.1089383953374368,
      "grad_norm": 1.1488254070281982,
      "learning_rate": 4.9153478167399524e-05,
      "loss": 1.6885,
      "step": 4840
    },
    {
      "epoch": 2.113295931150934,
      "grad_norm": 1.6331392526626587,
      "learning_rate": 4.8717534123603e-05,
      "loss": 1.7078,
      "step": 4850
    },
    {
      "epoch": 2.117653466964432,
      "grad_norm": 1.5641509294509888,
      "learning_rate": 4.8282908472830854e-05,
      "loss": 1.7277,
      "step": 4860
    },
    {
      "epoch": 2.122011002777929,
      "grad_norm": 1.0657570362091064,
      "learning_rate": 4.784961238863758e-05,
      "loss": 1.6531,
      "step": 4870
    },
    {
      "epoch": 2.1263685385914264,
      "grad_norm": 1.2061831951141357,
      "learning_rate": 4.741765701039653e-05,
      "loss": 1.6574,
      "step": 4880
    },
    {
      "epoch": 2.130726074404924,
      "grad_norm": 1.359961748123169,
      "learning_rate": 4.6987053443013614e-05,
      "loss": 1.7087,
      "step": 4890
    },
    {
      "epoch": 2.1350836102184214,
      "grad_norm": 1.1671441793441772,
      "learning_rate": 4.655781275664171e-05,
      "loss": 1.5446,
      "step": 4900
    },
    {
      "epoch": 2.139441146031919,
      "grad_norm": 1.4414092302322388,
      "learning_rate": 4.6129945986396284e-05,
      "loss": 1.7589,
      "step": 4910
    },
    {
      "epoch": 2.1437986818454164,
      "grad_norm": 1.372179388999939,
      "learning_rate": 4.570346413207128e-05,
      "loss": 1.5862,
      "step": 4920
    },
    {
      "epoch": 2.1481562176589137,
      "grad_norm": 1.1221579313278198,
      "learning_rate": 4.527837815785691e-05,
      "loss": 1.7137,
      "step": 4930
    },
    {
      "epoch": 2.1525137534724115,
      "grad_norm": 1.0010359287261963,
      "learning_rate": 4.485469899205712e-05,
      "loss": 1.6661,
      "step": 4940
    },
    {
      "epoch": 2.1568712892859088,
      "grad_norm": 1.1844310760498047,
      "learning_rate": 4.443243752680929e-05,
      "loss": 1.6142,
      "step": 4950
    },
    {
      "epoch": 2.161228825099406,
      "grad_norm": 1.1332595348358154,
      "learning_rate": 4.4011604617803756e-05,
      "loss": 1.623,
      "step": 4960
    },
    {
      "epoch": 2.165586360912904,
      "grad_norm": 1.4446126222610474,
      "learning_rate": 4.35922110840048e-05,
      "loss": 1.7617,
      "step": 4970
    },
    {
      "epoch": 2.169943896726401,
      "grad_norm": 1.3415168523788452,
      "learning_rate": 4.317426770737284e-05,
      "loss": 1.7293,
      "step": 4980
    },
    {
      "epoch": 2.174301432539899,
      "grad_norm": 1.139674186706543,
      "learning_rate": 4.275778523258668e-05,
      "loss": 1.6574,
      "step": 4990
    },
    {
      "epoch": 2.178658968353396,
      "grad_norm": 2.843775749206543,
      "learning_rate": 4.234277436676787e-05,
      "loss": 1.6635,
      "step": 5000
    },
    {
      "epoch": 2.178658968353396,
      "eval_loss": NaN,
      "eval_runtime": 1047.1103,
      "eval_samples_per_second": 3.591,
      "eval_steps_per_second": 3.591,
      "step": 5000
    },
    {
      "epoch": 2.1830165041668934,
      "grad_norm": 1.5717419385910034,
      "learning_rate": 4.192924577920502e-05,
      "loss": 1.7026,
      "step": 5010
    },
    {
      "epoch": 2.187374039980391,
      "grad_norm": 0.9739187955856323,
      "learning_rate": 4.151721010107967e-05,
      "loss": 1.6314,
      "step": 5020
    },
    {
      "epoch": 2.1917315757938884,
      "grad_norm": 1.3409173488616943,
      "learning_rate": 4.110667792519298e-05,
      "loss": 1.7126,
      "step": 5030
    },
    {
      "epoch": 2.196089111607386,
      "grad_norm": 1.3611998558044434,
      "learning_rate": 4.06976598056934e-05,
      "loss": 1.6664,
      "step": 5040
    },
    {
      "epoch": 2.2004466474208835,
      "grad_norm": 1.8917279243469238,
      "learning_rate": 4.029016625780528e-05,
      "loss": 1.7287,
      "step": 5050
    },
    {
      "epoch": 2.2048041832343808,
      "grad_norm": 1.3276914358139038,
      "learning_rate": 3.988420775755867e-05,
      "loss": 1.8298,
      "step": 5060
    },
    {
      "epoch": 2.2091617190478785,
      "grad_norm": 1.4140974283218384,
      "learning_rate": 3.947979474151977e-05,
      "loss": 1.5793,
      "step": 5070
    },
    {
      "epoch": 2.213519254861376,
      "grad_norm": 1.0128536224365234,
      "learning_rate": 3.9076937606523024e-05,
      "loss": 1.5801,
      "step": 5080
    },
    {
      "epoch": 2.2178767906748735,
      "grad_norm": 1.4811214208602905,
      "learning_rate": 3.867564670940324e-05,
      "loss": 1.6348,
      "step": 5090
    },
    {
      "epoch": 2.222234326488371,
      "grad_norm": 1.7273787260055542,
      "learning_rate": 3.827593236672998e-05,
      "loss": 1.6581,
      "step": 5100
    },
    {
      "epoch": 2.226591862301868,
      "grad_norm": 1.5387709140777588,
      "learning_rate": 3.787780485454181e-05,
      "loss": 1.7372,
      "step": 5110
    },
    {
      "epoch": 2.230949398115366,
      "grad_norm": 1.1165893077850342,
      "learning_rate": 3.748127440808239e-05,
      "loss": 1.6649,
      "step": 5120
    },
    {
      "epoch": 2.235306933928863,
      "grad_norm": 1.0123995542526245,
      "learning_rate": 3.708635122153743e-05,
      "loss": 1.6246,
      "step": 5130
    },
    {
      "epoch": 2.239664469742361,
      "grad_norm": 1.1084516048431396,
      "learning_rate": 3.66930454477722e-05,
      "loss": 1.7457,
      "step": 5140
    },
    {
      "epoch": 2.244022005555858,
      "grad_norm": 1.4356563091278076,
      "learning_rate": 3.630136719807103e-05,
      "loss": 1.5508,
      "step": 5150
    },
    {
      "epoch": 2.2483795413693555,
      "grad_norm": 1.326910138130188,
      "learning_rate": 3.5911326541877e-05,
      "loss": 1.7085,
      "step": 5160
    },
    {
      "epoch": 2.252737077182853,
      "grad_norm": 1.4540823698043823,
      "learning_rate": 3.55229335065332e-05,
      "loss": 1.7059,
      "step": 5170
    },
    {
      "epoch": 2.2570946129963505,
      "grad_norm": 1.0035423040390015,
      "learning_rate": 3.5136198077024926e-05,
      "loss": 1.6707,
      "step": 5180
    },
    {
      "epoch": 2.2614521488098482,
      "grad_norm": 1.5467814207077026,
      "learning_rate": 3.475113019572304e-05,
      "loss": 1.6379,
      "step": 5190
    },
    {
      "epoch": 2.2658096846233455,
      "grad_norm": 0.9280728697776794,
      "learning_rate": 3.436773976212825e-05,
      "loss": 1.7018,
      "step": 5200
    },
    {
      "epoch": 2.270167220436843,
      "grad_norm": 1.5620110034942627,
      "learning_rate": 3.39860366326167e-05,
      "loss": 1.7776,
      "step": 5210
    },
    {
      "epoch": 2.2745247562503406,
      "grad_norm": 1.339872121810913,
      "learning_rate": 3.3606030620186565e-05,
      "loss": 1.6216,
      "step": 5220
    },
    {
      "epoch": 2.278882292063838,
      "grad_norm": 1.116194725036621,
      "learning_rate": 3.322773149420575e-05,
      "loss": 1.6433,
      "step": 5230
    },
    {
      "epoch": 2.2832398278773356,
      "grad_norm": 1.3952008485794067,
      "learning_rate": 3.285114898016071e-05,
      "loss": 1.7889,
      "step": 5240
    },
    {
      "epoch": 2.287597363690833,
      "grad_norm": 1.0213984251022339,
      "learning_rate": 3.247629275940651e-05,
      "loss": 1.6932,
      "step": 5250
    },
    {
      "epoch": 2.287597363690833,
      "eval_loss": NaN,
      "eval_runtime": 1050.2903,
      "eval_samples_per_second": 3.58,
      "eval_steps_per_second": 3.58,
      "step": 5250
    },
    {
      "epoch": 2.29195489950433,
      "grad_norm": 1.6889023780822754,
      "learning_rate": 3.2103172468917864e-05,
      "loss": 1.7871,
      "step": 5260
    },
    {
      "epoch": 2.296312435317828,
      "grad_norm": 1.1724450588226318,
      "learning_rate": 3.173179770104134e-05,
      "loss": 1.6959,
      "step": 5270
    },
    {
      "epoch": 2.300669971131325,
      "grad_norm": 1.1925756931304932,
      "learning_rate": 3.136217800324899e-05,
      "loss": 1.689,
      "step": 5280
    },
    {
      "epoch": 2.305027506944823,
      "grad_norm": 1.2343450784683228,
      "learning_rate": 3.0994322877892434e-05,
      "loss": 1.6754,
      "step": 5290
    },
    {
      "epoch": 2.3093850427583202,
      "grad_norm": 1.3751485347747803,
      "learning_rate": 3.0628241781959185e-05,
      "loss": 1.7212,
      "step": 5300
    },
    {
      "epoch": 2.3137425785718175,
      "grad_norm": 0.9826796650886536,
      "learning_rate": 3.0263944126828913e-05,
      "loss": 1.6371,
      "step": 5310
    },
    {
      "epoch": 2.3181001143853153,
      "grad_norm": 1.640039086341858,
      "learning_rate": 2.9901439278031973e-05,
      "loss": 1.6248,
      "step": 5320
    },
    {
      "epoch": 2.3224576501988126,
      "grad_norm": 1.5732557773590088,
      "learning_rate": 2.9540736555008362e-05,
      "loss": 1.6886,
      "step": 5330
    },
    {
      "epoch": 2.32681518601231,
      "grad_norm": 0.9867480397224426,
      "learning_rate": 2.91818452308682e-05,
      "loss": 1.6271,
      "step": 5340
    },
    {
      "epoch": 2.3311727218258076,
      "grad_norm": 1.1364954710006714,
      "learning_rate": 2.8824774532153353e-05,
      "loss": 1.6704,
      "step": 5350
    },
    {
      "epoch": 2.335530257639305,
      "grad_norm": 1.7834196090698242,
      "learning_rate": 2.846953363860021e-05,
      "loss": 1.7592,
      "step": 5360
    },
    {
      "epoch": 2.3398877934528026,
      "grad_norm": 1.217400312423706,
      "learning_rate": 2.8116131682903713e-05,
      "loss": 1.6175,
      "step": 5370
    },
    {
      "epoch": 2.3442453292663,
      "grad_norm": 1.0709172487258911,
      "learning_rate": 2.7764577750482523e-05,
      "loss": 1.6242,
      "step": 5380
    },
    {
      "epoch": 2.348602865079797,
      "grad_norm": 1.6009025573730469,
      "learning_rate": 2.7414880879245508e-05,
      "loss": 1.5739,
      "step": 5390
    },
    {
      "epoch": 2.352960400893295,
      "grad_norm": 1.3568265438079834,
      "learning_rate": 2.7067050059359324e-05,
      "loss": 1.7816,
      "step": 5400
    },
    {
      "epoch": 2.3573179367067922,
      "grad_norm": 1.6784145832061768,
      "learning_rate": 2.6721094233017342e-05,
      "loss": 1.6441,
      "step": 5410
    },
    {
      "epoch": 2.3616754725202895,
      "grad_norm": 1.4022995233535767,
      "learning_rate": 2.6377022294209774e-05,
      "loss": 1.6035,
      "step": 5420
    },
    {
      "epoch": 2.3660330083337873,
      "grad_norm": 1.1218630075454712,
      "learning_rate": 2.603484308849493e-05,
      "loss": 1.6529,
      "step": 5430
    },
    {
      "epoch": 2.3703905441472846,
      "grad_norm": 1.4618765115737915,
      "learning_rate": 2.569456541277191e-05,
      "loss": 1.7438,
      "step": 5440
    },
    {
      "epoch": 2.3747480799607823,
      "grad_norm": 1.4410004615783691,
      "learning_rate": 2.53561980150545e-05,
      "loss": 1.6593,
      "step": 5450
    },
    {
      "epoch": 2.3791056157742796,
      "grad_norm": 1.1448464393615723,
      "learning_rate": 2.5019749594245967e-05,
      "loss": 1.6037,
      "step": 5460
    },
    {
      "epoch": 2.383463151587777,
      "grad_norm": 1.848568320274353,
      "learning_rate": 2.4685228799915905e-05,
      "loss": 1.6035,
      "step": 5470
    },
    {
      "epoch": 2.3878206874012746,
      "grad_norm": 1.4325122833251953,
      "learning_rate": 2.435264423207736e-05,
      "loss": 1.6285,
      "step": 5480
    },
    {
      "epoch": 2.392178223214772,
      "grad_norm": 1.29388427734375,
      "learning_rate": 2.4022004440966195e-05,
      "loss": 1.7227,
      "step": 5490
    },
    {
      "epoch": 2.3965357590282697,
      "grad_norm": 1.9302499294281006,
      "learning_rate": 2.3693317926820946e-05,
      "loss": 1.6234,
      "step": 5500
    },
    {
      "epoch": 2.3965357590282697,
      "eval_loss": NaN,
      "eval_runtime": 1043.7343,
      "eval_samples_per_second": 3.602,
      "eval_steps_per_second": 3.602,
      "step": 5500
    },
    {
      "epoch": 2.400893294841767,
      "grad_norm": 1.9352807998657227,
      "learning_rate": 2.336659313966444e-05,
      "loss": 1.6246,
      "step": 5510
    },
    {
      "epoch": 2.4052508306552642,
      "grad_norm": 1.3868842124938965,
      "learning_rate": 2.3041838479086542e-05,
      "loss": 1.7182,
      "step": 5520
    },
    {
      "epoch": 2.409608366468762,
      "grad_norm": 0.8889657855033875,
      "learning_rate": 2.2719062294028202e-05,
      "loss": 1.8433,
      "step": 5530
    },
    {
      "epoch": 2.4139659022822593,
      "grad_norm": 1.3348901271820068,
      "learning_rate": 2.2398272882566795e-05,
      "loss": 1.7699,
      "step": 5540
    },
    {
      "epoch": 2.418323438095757,
      "grad_norm": 1.5021588802337646,
      "learning_rate": 2.2079478491702854e-05,
      "loss": 1.6778,
      "step": 5550
    },
    {
      "epoch": 2.4226809739092543,
      "grad_norm": 1.0488359928131104,
      "learning_rate": 2.176268731714798e-05,
      "loss": 1.7884,
      "step": 5560
    },
    {
      "epoch": 2.4270385097227516,
      "grad_norm": 1.2831217050552368,
      "learning_rate": 2.1447907503114183e-05,
      "loss": 1.6576,
      "step": 5570
    },
    {
      "epoch": 2.4313960455362493,
      "grad_norm": 1.058140754699707,
      "learning_rate": 2.1135147142104528e-05,
      "loss": 1.6963,
      "step": 5580
    },
    {
      "epoch": 2.4357535813497466,
      "grad_norm": 1.1032323837280273,
      "learning_rate": 2.0824414274705007e-05,
      "loss": 1.7245,
      "step": 5590
    },
    {
      "epoch": 2.4401111171632444,
      "grad_norm": 1.2651326656341553,
      "learning_rate": 2.0515716889377935e-05,
      "loss": 1.6469,
      "step": 5600
    },
    {
      "epoch": 2.4444686529767417,
      "grad_norm": 1.515989065170288,
      "learning_rate": 2.020906292225645e-05,
      "loss": 1.6373,
      "step": 5610
    },
    {
      "epoch": 2.448826188790239,
      "grad_norm": 1.5013943910598755,
      "learning_rate": 1.9904460256940715e-05,
      "loss": 1.5565,
      "step": 5620
    },
    {
      "epoch": 2.4531837246037367,
      "grad_norm": 1.3351746797561646,
      "learning_rate": 1.9601916724294868e-05,
      "loss": 1.6619,
      "step": 5630
    },
    {
      "epoch": 2.457541260417234,
      "grad_norm": 1.1063857078552246,
      "learning_rate": 1.930144010224616e-05,
      "loss": 1.6909,
      "step": 5640
    },
    {
      "epoch": 2.4618987962307317,
      "grad_norm": 1.8119981288909912,
      "learning_rate": 1.900303811558455e-05,
      "loss": 1.6764,
      "step": 5650
    },
    {
      "epoch": 2.466256332044229,
      "grad_norm": 1.5162367820739746,
      "learning_rate": 1.870671843576448e-05,
      "loss": 1.6756,
      "step": 5660
    },
    {
      "epoch": 2.4706138678577263,
      "grad_norm": 2.3985302448272705,
      "learning_rate": 1.841248868070746e-05,
      "loss": 1.6079,
      "step": 5670
    },
    {
      "epoch": 2.474971403671224,
      "grad_norm": 1.7051881551742554,
      "learning_rate": 1.8120356414606154e-05,
      "loss": 1.7351,
      "step": 5680
    },
    {
      "epoch": 2.4793289394847213,
      "grad_norm": 1.325011134147644,
      "learning_rate": 1.7830329147730217e-05,
      "loss": 1.6163,
      "step": 5690
    },
    {
      "epoch": 2.483686475298219,
      "grad_norm": 1.1487566232681274,
      "learning_rate": 1.7542414336232817e-05,
      "loss": 1.8247,
      "step": 5700
    },
    {
      "epoch": 2.4880440111117164,
      "grad_norm": 0.9152500629425049,
      "learning_rate": 1.7256619381959315e-05,
      "loss": 1.7445,
      "step": 5710
    },
    {
      "epoch": 2.4924015469252137,
      "grad_norm": 1.183688759803772,
      "learning_rate": 1.697295163225675e-05,
      "loss": 1.6805,
      "step": 5720
    },
    {
      "epoch": 2.4967590827387114,
      "grad_norm": 1.5116113424301147,
      "learning_rate": 1.6691418379785006e-05,
      "loss": 1.7323,
      "step": 5730
    },
    {
      "epoch": 2.5011166185522087,
      "grad_norm": 1.5475876331329346,
      "learning_rate": 1.6412026862329365e-05,
      "loss": 1.7198,
      "step": 5740
    },
    {
      "epoch": 2.5054741543657064,
      "grad_norm": 1.1402744054794312,
      "learning_rate": 1.61347842626144e-05,
      "loss": 1.6316,
      "step": 5750
    },
    {
      "epoch": 2.5054741543657064,
      "eval_loss": NaN,
      "eval_runtime": 1074.8629,
      "eval_samples_per_second": 3.498,
      "eval_steps_per_second": 3.498,
      "step": 5750
    },
    {
      "epoch": 2.5098316901792037,
      "grad_norm": 1.5560344457626343,
      "learning_rate": 1.5859697708119325e-05,
      "loss": 1.729,
      "step": 5760
    },
    {
      "epoch": 2.514189225992701,
      "grad_norm": 1.7389360666275024,
      "learning_rate": 1.5586774270894743e-05,
      "loss": 1.7115,
      "step": 5770
    },
    {
      "epoch": 2.5185467618061987,
      "grad_norm": 1.227187991142273,
      "learning_rate": 1.531602096738085e-05,
      "loss": 1.735,
      "step": 5780
    },
    {
      "epoch": 2.522904297619696,
      "grad_norm": 1.7991465330123901,
      "learning_rate": 1.5047444758227158e-05,
      "loss": 1.6451,
      "step": 5790
    },
    {
      "epoch": 2.5272618334331938,
      "grad_norm": 1.3998479843139648,
      "learning_rate": 1.478105254811325e-05,
      "loss": 1.666,
      "step": 5800
    },
    {
      "epoch": 2.531619369246691,
      "grad_norm": 1.4503624439239502,
      "learning_rate": 1.4516851185571679e-05,
      "loss": 1.6942,
      "step": 5810
    },
    {
      "epoch": 2.5359769050601884,
      "grad_norm": 1.761141300201416,
      "learning_rate": 1.4254847462811494e-05,
      "loss": 1.7367,
      "step": 5820
    },
    {
      "epoch": 2.540334440873686,
      "grad_norm": 1.0446370840072632,
      "learning_rate": 1.3995048115543929e-05,
      "loss": 1.7262,
      "step": 5830
    },
    {
      "epoch": 2.5446919766871834,
      "grad_norm": 1.74695885181427,
      "learning_rate": 1.3737459822809162e-05,
      "loss": 1.7342,
      "step": 5840
    },
    {
      "epoch": 2.549049512500681,
      "grad_norm": 1.0211533308029175,
      "learning_rate": 1.3482089206804426e-05,
      "loss": 1.5471,
      "step": 5850
    },
    {
      "epoch": 2.5534070483141784,
      "grad_norm": 1.0936040878295898,
      "learning_rate": 1.3228942832714109e-05,
      "loss": 1.6999,
      "step": 5860
    },
    {
      "epoch": 2.5577645841276757,
      "grad_norm": 1.1363252401351929,
      "learning_rate": 1.2978027208540556e-05,
      "loss": 1.5909,
      "step": 5870
    },
    {
      "epoch": 2.562122119941173,
      "grad_norm": 1.2108575105667114,
      "learning_rate": 1.2729348784937157e-05,
      "loss": 1.6823,
      "step": 5880
    },
    {
      "epoch": 2.5664796557546707,
      "grad_norm": 1.21621835231781,
      "learning_rate": 1.248291395504223e-05,
      "loss": 1.7488,
      "step": 5890
    },
    {
      "epoch": 2.5708371915681685,
      "grad_norm": 1.8846964836120605,
      "learning_rate": 1.2238729054314801e-05,
      "loss": 1.6143,
      "step": 5900
    },
    {
      "epoch": 2.5751947273816658,
      "grad_norm": 2.5891757011413574,
      "learning_rate": 1.1996800360371663e-05,
      "loss": 1.6267,
      "step": 5910
    },
    {
      "epoch": 2.579552263195163,
      "grad_norm": 1.6483440399169922,
      "learning_rate": 1.175713409282605e-05,
      "loss": 1.7481,
      "step": 5920
    },
    {
      "epoch": 2.5839097990086604,
      "grad_norm": 1.5117621421813965,
      "learning_rate": 1.1519736413127668e-05,
      "loss": 1.6991,
      "step": 5930
    },
    {
      "epoch": 2.588267334822158,
      "grad_norm": 1.2010358572006226,
      "learning_rate": 1.1284613424404367e-05,
      "loss": 1.7053,
      "step": 5940
    },
    {
      "epoch": 2.5926248706356554,
      "grad_norm": 1.2872157096862793,
      "learning_rate": 1.105177117130518e-05,
      "loss": 1.6442,
      "step": 5950
    },
    {
      "epoch": 2.596982406449153,
      "grad_norm": 1.435148000717163,
      "learning_rate": 1.0821215639844961e-05,
      "loss": 1.7501,
      "step": 5960
    },
    {
      "epoch": 2.6013399422626504,
      "grad_norm": 1.679835557937622,
      "learning_rate": 1.0592952757250474e-05,
      "loss": 1.7759,
      "step": 5970
    },
    {
      "epoch": 2.6056974780761477,
      "grad_norm": 2.036045789718628,
      "learning_rate": 1.036698839180803e-05,
      "loss": 1.7379,
      "step": 5980
    },
    {
      "epoch": 2.6100550138896454,
      "grad_norm": 1.4826934337615967,
      "learning_rate": 1.014332835271259e-05,
      "loss": 1.6333,
      "step": 5990
    },
    {
      "epoch": 2.6144125497031427,
      "grad_norm": 1.1679069995880127,
      "learning_rate": 9.921978389918452e-06,
      "loss": 1.6869,
      "step": 6000
    },
    {
      "epoch": 2.6144125497031427,
      "eval_loss": NaN,
      "eval_runtime": 1045.8134,
      "eval_samples_per_second": 3.595,
      "eval_steps_per_second": 3.595,
      "step": 6000
    },
    {
      "epoch": 2.6187700855166405,
      "grad_norm": 0.9742734432220459,
      "learning_rate": 9.70294419399148e-06,
      "loss": 1.5317,
      "step": 6010
    },
    {
      "epoch": 2.6231276213301378,
      "grad_norm": 1.2264291048049927,
      "learning_rate": 9.48623139596262e-06,
      "loss": 1.605,
      "step": 6020
    },
    {
      "epoch": 2.627485157143635,
      "grad_norm": 1.3564926385879517,
      "learning_rate": 9.27184556718339e-06,
      "loss": 1.5947,
      "step": 6030
    },
    {
      "epoch": 2.631842692957133,
      "grad_norm": 1.6650855541229248,
      "learning_rate": 9.059792219182405e-06,
      "loss": 1.6735,
      "step": 6040
    },
    {
      "epoch": 2.63620022877063,
      "grad_norm": 1.1344529390335083,
      "learning_rate": 8.85007680352392e-06,
      "loss": 1.6512,
      "step": 6050
    },
    {
      "epoch": 2.640557764584128,
      "grad_norm": 1.7561835050582886,
      "learning_rate": 8.64270471166747e-06,
      "loss": 1.7097,
      "step": 6060
    },
    {
      "epoch": 2.644915300397625,
      "grad_norm": 1.9605375528335571,
      "learning_rate": 8.43768127482939e-06,
      "loss": 1.6712,
      "step": 6070
    },
    {
      "epoch": 2.6492728362111224,
      "grad_norm": 1.4681156873703003,
      "learning_rate": 8.235011763845713e-06,
      "loss": 1.6573,
      "step": 6080
    },
    {
      "epoch": 2.65363037202462,
      "grad_norm": 1.3124477863311768,
      "learning_rate": 8.034701389036658e-06,
      "loss": 1.6988,
      "step": 6090
    },
    {
      "epoch": 2.6579879078381174,
      "grad_norm": 1.3668369054794312,
      "learning_rate": 7.836755300072717e-06,
      "loss": 1.602,
      "step": 6100
    },
    {
      "epoch": 2.662345443651615,
      "grad_norm": 1.746969223022461,
      "learning_rate": 7.641178585842234e-06,
      "loss": 1.7901,
      "step": 6110
    },
    {
      "epoch": 2.6667029794651125,
      "grad_norm": 1.3492324352264404,
      "learning_rate": 7.447976274320601e-06,
      "loss": 1.5872,
      "step": 6120
    },
    {
      "epoch": 2.6710605152786098,
      "grad_norm": 1.245728850364685,
      "learning_rate": 7.257153332440947e-06,
      "loss": 1.7426,
      "step": 6130
    },
    {
      "epoch": 2.6754180510921075,
      "grad_norm": 1.4759173393249512,
      "learning_rate": 7.068714665966514e-06,
      "loss": 1.6455,
      "step": 6140
    },
    {
      "epoch": 2.679775586905605,
      "grad_norm": 1.0929049253463745,
      "learning_rate": 6.882665119364485e-06,
      "loss": 1.7194,
      "step": 6150
    },
    {
      "epoch": 2.6841331227191025,
      "grad_norm": 1.7265642881393433,
      "learning_rate": 6.699009475681483e-06,
      "loss": 1.7154,
      "step": 6160
    },
    {
      "epoch": 2.6884906585326,
      "grad_norm": 1.1897257566452026,
      "learning_rate": 6.517752456420534e-06,
      "loss": 1.6369,
      "step": 6170
    },
    {
      "epoch": 2.692848194346097,
      "grad_norm": 1.1520112752914429,
      "learning_rate": 6.338898721419828e-06,
      "loss": 1.7221,
      "step": 6180
    },
    {
      "epoch": 2.697205730159595,
      "grad_norm": 1.8117685317993164,
      "learning_rate": 6.162452868732693e-06,
      "loss": 1.7422,
      "step": 6190
    },
    {
      "epoch": 2.701563265973092,
      "grad_norm": 1.0782191753387451,
      "learning_rate": 5.98841943450964e-06,
      "loss": 1.6858,
      "step": 6200
    },
    {
      "epoch": 2.70592080178659,
      "grad_norm": 1.1968379020690918,
      "learning_rate": 5.816802892881568e-06,
      "loss": 1.6685,
      "step": 6210
    },
    {
      "epoch": 2.710278337600087,
      "grad_norm": 1.1805311441421509,
      "learning_rate": 5.647607655844811e-06,
      "loss": 1.6738,
      "step": 6220
    },
    {
      "epoch": 2.7146358734135845,
      "grad_norm": 1.1053887605667114,
      "learning_rate": 5.4808380731476874e-06,
      "loss": 1.7274,
      "step": 6230
    },
    {
      "epoch": 2.718993409227082,
      "grad_norm": 1.286784291267395,
      "learning_rate": 5.316498432178707e-06,
      "loss": 1.6062,
      "step": 6240
    },
    {
      "epoch": 2.7233509450405795,
      "grad_norm": 1.4054964780807495,
      "learning_rate": 5.154592957856319e-06,
      "loss": 1.6251,
      "step": 6250
    },
    {
      "epoch": 2.7233509450405795,
      "eval_loss": NaN,
      "eval_runtime": 1046.7919,
      "eval_samples_per_second": 3.592,
      "eval_steps_per_second": 3.592,
      "step": 6250
    },
    {
      "epoch": 2.7277084808540772,
      "grad_norm": 1.347023606300354,
      "learning_rate": 4.995125812520307e-06,
      "loss": 1.6632,
      "step": 6260
    },
    {
      "epoch": 2.7320660166675745,
      "grad_norm": 1.0992127656936646,
      "learning_rate": 4.838101095824776e-06,
      "loss": 1.6881,
      "step": 6270
    },
    {
      "epoch": 2.736423552481072,
      "grad_norm": 1.3625845909118652,
      "learning_rate": 4.6835228446327815e-06,
      "loss": 1.6376,
      "step": 6280
    },
    {
      "epoch": 2.7407810882945696,
      "grad_norm": 1.064439296722412,
      "learning_rate": 4.5313950329125e-06,
      "loss": 1.6907,
      "step": 6290
    },
    {
      "epoch": 2.745138624108067,
      "grad_norm": 1.3763278722763062,
      "learning_rate": 4.381721571635123e-06,
      "loss": 1.7107,
      "step": 6300
    },
    {
      "epoch": 2.7494961599215646,
      "grad_norm": 1.4681061506271362,
      "learning_rate": 4.234506308674235e-06,
      "loss": 1.6026,
      "step": 6310
    },
    {
      "epoch": 2.753853695735062,
      "grad_norm": 1.405724287033081,
      "learning_rate": 4.089753028706988e-06,
      "loss": 1.8011,
      "step": 6320
    },
    {
      "epoch": 2.758211231548559,
      "grad_norm": 1.7786083221435547,
      "learning_rate": 3.947465453116728e-06,
      "loss": 1.7432,
      "step": 6330
    },
    {
      "epoch": 2.762568767362057,
      "grad_norm": 1.0740288496017456,
      "learning_rate": 3.8076472398973384e-06,
      "loss": 1.7215,
      "step": 6340
    },
    {
      "epoch": 2.766926303175554,
      "grad_norm": 1.8521182537078857,
      "learning_rate": 3.6703019835592433e-06,
      "loss": 1.6221,
      "step": 6350
    },
    {
      "epoch": 2.771283838989052,
      "grad_norm": 1.002873182296753,
      "learning_rate": 3.5354332150369094e-06,
      "loss": 1.5827,
      "step": 6360
    },
    {
      "epoch": 2.7756413748025492,
      "grad_norm": 1.134277582168579,
      "learning_rate": 3.4030444015981767e-06,
      "loss": 1.7191,
      "step": 6370
    },
    {
      "epoch": 2.7799989106160465,
      "grad_norm": 1.402457594871521,
      "learning_rate": 3.273138946755061e-06,
      "loss": 1.7042,
      "step": 6380
    },
    {
      "epoch": 2.784356446429544,
      "grad_norm": 1.42952561378479,
      "learning_rate": 3.145720190176216e-06,
      "loss": 1.7478,
      "step": 6390
    },
    {
      "epoch": 2.7887139822430416,
      "grad_norm": 1.3246495723724365,
      "learning_rate": 3.020791407601187e-06,
      "loss": 1.7266,
      "step": 6400
    },
    {
      "epoch": 2.7930715180565393,
      "grad_norm": 1.752851128578186,
      "learning_rate": 2.898355810756059e-06,
      "loss": 1.6611,
      "step": 6410
    },
    {
      "epoch": 2.7974290538700366,
      "grad_norm": 1.564607858657837,
      "learning_rate": 2.7784165472710564e-06,
      "loss": 1.747,
      "step": 6420
    },
    {
      "epoch": 2.801786589683534,
      "grad_norm": 1.1393088102340698,
      "learning_rate": 2.6609767005994268e-06,
      "loss": 1.7459,
      "step": 6430
    },
    {
      "epoch": 2.806144125497031,
      "grad_norm": 1.1096515655517578,
      "learning_rate": 2.546039289938351e-06,
      "loss": 1.5613,
      "step": 6440
    },
    {
      "epoch": 2.810501661310529,
      "grad_norm": 1.3372215032577515,
      "learning_rate": 2.4336072701511947e-06,
      "loss": 1.7621,
      "step": 6450
    },
    {
      "epoch": 2.814859197124026,
      "grad_norm": 1.3346037864685059,
      "learning_rate": 2.3236835316916007e-06,
      "loss": 1.6986,
      "step": 6460
    },
    {
      "epoch": 2.819216732937524,
      "grad_norm": 1.4879248142242432,
      "learning_rate": 2.2162709005291827e-06,
      "loss": 1.7008,
      "step": 6470
    },
    {
      "epoch": 2.8235742687510212,
      "grad_norm": 1.1706982851028442,
      "learning_rate": 2.11137213807685e-06,
      "loss": 1.7377,
      "step": 6480
    },
    {
      "epoch": 2.8279318045645185,
      "grad_norm": 0.9295700192451477,
      "learning_rate": 2.0089899411198433e-06,
      "loss": 1.6483,
      "step": 6490
    },
    {
      "epoch": 2.8322893403780163,
      "grad_norm": 1.1315999031066895,
      "learning_rate": 1.9091269417463977e-06,
      "loss": 1.6133,
      "step": 6500
    },
    {
      "epoch": 2.8322893403780163,
      "eval_loss": NaN,
      "eval_runtime": 2496.4173,
      "eval_samples_per_second": 1.506,
      "eval_steps_per_second": 1.506,
      "step": 6500
    }
  ],
  "logging_steps": 10,
  "max_steps": 6885,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.960358705644175e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
